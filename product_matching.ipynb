{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nancy-kataria/NexTrade/blob/main/product_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== Imports ==="
      ],
      "metadata": {
        "id": "TxLsn_3YgSds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FQjFG7BkiGKB"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "metadata": {
        "id": "cBKpCzmXbrpJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 1. Dataset Download ==="
      ],
      "metadata": {
        "id": "BitMW-zx-j2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "print(\"Dowlaod Dataset...\")\n",
        "path = kagglehub.dataset_download(\"vivek468/superstore-dataset-final\")\n",
        "print(f\"Dataset downloaded to: {path}\")\n",
        "csv_file_path = os.path.join(path, \"Sample - Superstore.csv\")\n",
        "print(f\"Reading data from: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "xj6z5B1j-nv7",
        "outputId": "54071fd1-07df-4f14-ac36-779e9381246b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dowlaod Dataset...\n",
            "Dataset downloaded to: /kaggle/input/superstore-dataset-final\n",
            "Reading data from: /kaggle/input/superstore-dataset-final/Sample - Superstore.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 2. Load & Clean Data ==="
      ],
      "metadata": {
        "id": "0fos8cod7pJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    superstore_data = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {csv_file_path}.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "Mh4kbf0HjNH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d14e34-2807-4924-a398-abc1806374d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep necessary columns\n",
        "columns_to_keep = ['Order ID', 'Order Date', 'Ship Date', 'Customer ID', 'Product ID', 'Product Name', 'Sales', 'Quantity', 'Category', 'Sub-Category']\n",
        "superstore_data = superstore_data[columns_to_keep]"
      ],
      "metadata": {
        "id": "_fTuhoxWlcUH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows to check the data\n",
        "print(\"First 5 rows of data:\")\n",
        "print(superstore_data.head())"
      ],
      "metadata": {
        "id": "4bSD5nfglcFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dates\n",
        "superstore_data['Order Date'] = pd.to_datetime(superstore_data['Order Date'])\n",
        "superstore_data['Ship Date'] = pd.to_datetime(superstore_data['Ship Date'])"
      ],
      "metadata": {
        "id": "v8JDsd7ZkKAk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if dropna() is overkill\n",
        "print(superstore_data[columns_to_keep].isnull().sum())"
      ],
      "metadata": {
        "id": "C96ihRBJcYV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop rows with missing any necessary columns\n",
        "superstore_data.dropna(subset=columns_to_keep, inplace=True)"
      ],
      "metadata": {
        "id": "omwT_AcdkKXc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Finding Customers with Most Transactions ---\")\n",
        "\n",
        "# Count the number of rows (transaction line items) for each Customer ID\n",
        "customer_transaction_counts = superstore_data.groupby('Customer ID').size()\n",
        "\n",
        "# Sort the counts in descending order\n",
        "customer_transaction_counts_sorted = customer_transaction_counts.sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 5 Customers by Number of Transaction Entries:\")\n",
        "print(customer_transaction_counts_sorted.head(5))\n",
        "\n",
        "# Get the Customer ID with the absolute highest count\n",
        "if not customer_transaction_counts_sorted.empty:\n",
        "    top_customer_id = customer_transaction_counts_sorted.index[0]\n",
        "    top_customer_count = customer_transaction_counts_sorted.iloc[0]\n",
        "    print(f\"\\nCustomer with the most transaction entries: '{top_customer_id}' ({top_customer_count} entries)\")\n",
        "else:\n",
        "    top_customer_id = None # Handle case where data might be empty\n",
        "    print(\"\\nCould not determine top customer.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCw9orMdu8YU",
        "outputId": "3690284b-fba6-462e-aaae-82da69083539"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Finding Customers with Most Transactions ---\n",
            "Top 5 Customers by Number of Transaction Entries:\n",
            "Customer ID\n",
            "WB-21850    37\n",
            "MA-17560    34\n",
            "JL-15835    34\n",
            "PP-18955    34\n",
            "EH-13765    32\n",
            "dtype: int64\n",
            "\n",
            "Customer with the most transaction entries: 'WB-21850' (37 entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== (TEST STAGE) 2b. Evaluation Split (Time-Based) ==="
      ],
      "metadata": {
        "id": "n-pBRT2gpfWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Splitting Data by User (Time-Based) ---\")\n",
        "\n",
        "train_records = []\n",
        "test_records = []\n",
        "\n",
        "# Group by user and sort each user's history by date\n",
        "user_groups = superstore_data.groupby('Customer ID')\n",
        "\n",
        "for user, group in user_groups:\n",
        "    if len(group) < 2:\n",
        "        continue  # skip users with less than 2 purchases\n",
        "\n",
        "    group_sorted = group.sort_values('Order Date')\n",
        "    split_idx = int(len(group_sorted) * 0.8)\n",
        "\n",
        "    train_records.append(group_sorted.iloc[:split_idx])\n",
        "    test_records.append(group_sorted.iloc[split_idx:])\n",
        "\n",
        "# Combine all into DataFrames\n",
        "train_df = pd.concat(train_records).reset_index(drop=True)\n",
        "test_df = pd.concat(test_records).reset_index(drop=True)\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "print(f\"Train period: {train_df['Order Date'].min()} → {train_df['Order Date'].max()}\")\n",
        "print(f\"Test period: {test_df['Order Date'].min()} → {test_df['Order Date'].max()}\")\n",
        "\n",
        "test_user_items = defaultdict(set)\n",
        "for _, row in test_df.iterrows():\n",
        "    test_user_items[row['Customer ID']].add(row['Product ID'])\n",
        "\n",
        "test_users = list(test_user_items.keys())\n",
        "print(f\"Number of test users: {len(test_users)}\")"
      ],
      "metadata": {
        "id": "0wNF5fG4pj3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00772c0f-b64e-42d1-e98b-2ecf38cc1b16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Splitting Data by User (Time-Based) ---\n",
            "Train shape: (7688, 11)\n",
            "Test shape: (2301, 11)\n",
            "Train period: 2014-01-03 00:00:00 → 2017-12-29 00:00:00\n",
            "Test period: 2014-10-10 00:00:00 → 2017-12-30 00:00:00\n",
            "Number of test users: 788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 3. Precomputation  ==="
      ],
      "metadata": {
        "id": "go59KyXFg9VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Product Popularity\n",
        "product_popularity = superstore_data.groupby('Product ID').agg({\n",
        "    'Product Name': 'first',\n",
        "    'Category': 'first',\n",
        "    'Sub-Category': 'first',\n",
        "    'Quantity': 'sum',\n",
        "    'Sales': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Normalize popularity score\n",
        "product_popularity['popularity_score'] = product_popularity['Quantity'] / product_popularity['Quantity'].max()\n",
        "\n",
        "# 2. Content-Based Info Preparation\n",
        "superstore_data['product_info'] = (\n",
        "    superstore_data['Product Name'].astype(str) + ' ' +\n",
        "    superstore_data['Category'].astype(str) + ' ' +\n",
        "    superstore_data['Sub-Category'].astype(str)\n",
        ")\n",
        "\n",
        "# One row per product\n",
        "products = superstore_data.drop_duplicates(subset='Product ID')[\n",
        "    ['Product ID', 'Product Name', 'Category', 'Sub-Category', 'product_info']\n",
        "]\n",
        "\n",
        "# 3. TF-IDF Matrix and Cosine Similarity\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(products['product_info'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 4. Product Index Mapping\n",
        "product_indices = pd.Series(data=range(len(products)), index=products['Product ID']).drop_duplicates()\n",
        "\n",
        "# 5. User-Product Matrix and Product Similarity for Collaborative Filtering\n",
        "# Create user-product interaction matrix\n",
        "user_product_matrix = superstore_data.pivot_table(\n",
        "    index='Customer ID',\n",
        "    columns='Product ID',\n",
        "    values='Quantity',\n",
        "    aggfunc='sum'\n",
        ").fillna(0)\n",
        "\n",
        "# Compute item-item similarity - similar to item you liked\n",
        "product_similarity = cosine_similarity(user_product_matrix.T)\n",
        "\n",
        "# Store as DataFrame\n",
        "product_similarity_df = pd.DataFrame(\n",
        "    product_similarity,\n",
        "    index=user_product_matrix.columns,\n",
        "    columns=user_product_matrix.columns\n",
        ")"
      ],
      "metadata": {
        "id": "c9fGWIFgg_Mp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 4. Recommendation Functions ==="
      ],
      "metadata": {
        "id": "M0vdvNDY7zWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Helper Functions ===\n",
        "def get_customer_orders_and_products(customer_id, df):\n",
        "    \"\"\"Fetches purchase data and unique purchased product IDs for a customer.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the target customer.\n",
        "        df (pd.DataFrame): The main DataFrame containing all transaction data.\n",
        "                           Must include 'Customer ID' and 'Product ID'.\n",
        "\n",
        "    Returns:\n",
        "        tuple[pd.DataFrame, np.ndarray]: A tuple containing:\n",
        "            - order_history (pd.DataFrame): A DataFrame filtered to only include\n",
        "                                            rows for the given customer_id. Returns\n",
        "                                            an empty DataFrame if customer not found.\n",
        "            - product_ids (np.ndarray): A NumPy array of unique Product IDs\n",
        "                                          purchased by the customer. Returns an\n",
        "                                          empty array if customer not found.\n",
        "    \"\"\"\n",
        "    order_history = df[df['Customer ID'] == customer_id].copy()\n",
        "    # Using .copy() is good practice here to prevent potential SettingWithCopyWarning\n",
        "    # if the returned DataFrame is modified later in another function.\n",
        "    product_ids = order_history['Product ID'].unique()\n",
        "    return order_history, product_ids\n",
        "\n",
        "def get_unseen_products(customer_id, df, product_df):\n",
        "    \"\"\"\n",
        "    Get a list of products the customer hasn't purchased yet\n",
        "\n",
        "    Args:\n",
        "      customer_id (str): ID of the target customer.\n",
        "      df (pd.DataFrame): Full transaction data (e.g., superstore_data)\n",
        "                           used to find customer history.\n",
        "      product_df (pd.DataFrame): DataFrame of all products to recommend\n",
        "                                   from (e.g., product_popularity).\n",
        "\n",
        "    Returns:\n",
        "      pd.DataFrame: filtered product_df with only unseen products\n",
        "      pd.DataFrame: list of purchased Product IDs for fallback logic\n",
        "    \"\"\"\n",
        "\n",
        "    _, product_ids = get_customer_orders_and_products(customer_id, df)\n",
        "    return product_df[~product_df['Product ID'].isin(product_ids)], product_ids\n",
        "\n",
        "def add_fallback_if_needed(recommendations, product_ids, product_df, n, by):\n",
        "    \"\"\"\n",
        "    Add fallback recommendations if there aren't enough unseen products to recommend\n",
        "    This uses globally popular products (based on 'Quantity' or 'Sales') to fill the gap\n",
        "\n",
        "    Args:\n",
        "      recommendations: filtered list of unseen, ranked products\n",
        "      purchased_ids: list of already purchased product IDs\n",
        "      product_df: global product list (e.g., product_popularity)\n",
        "      n: number of products we want to recommend\n",
        "      by: popularity metric ('Quantity' or 'Sales')\n",
        "\n",
        "    Returns:\n",
        "     pd.DataFrame: final DataFrame of n recommendations\n",
        "    \"\"\"\n",
        "\n",
        "    if len(recommendations) < n:\n",
        "        print(f\"Customer has only {len(recommendations)} new products available. Showing global popular items instead.\")\n",
        "        fallback = get_global_popular_products(top_n=n, by=by)\n",
        "        fallback = fallback[~fallback['Product ID'].isin(product_ids)]\n",
        "        recommendations = pd.concat([recommendations, fallback]).drop_duplicates('Product ID')\n",
        "    return recommendations\n",
        "\n",
        "def get_customer_preferences(customer_id, df):\n",
        "    \"\"\"\n",
        "    Gets the customer's most frequent categories and sub-categories.\n",
        "\n",
        "    Analyzes a customer's purchase history to find the categories and\n",
        "    sub-categories they interact with most often, based on the count\n",
        "    of purchases in each. Used for personalized popularity recommendations.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the target customer.\n",
        "        df (pd.DataFrame): The DataFrame containing transaction data, including\n",
        "                           'Customer ID', 'Category', and 'Sub-Category' columns.\n",
        "\n",
        "    Returns:\n",
        "        tuple[list[str], list[str]]: A tuple containing two lists:\n",
        "            - The first list contains category names, sorted by frequency (most frequent first).\n",
        "            - The second list contains sub-category names, sorted by frequency.\n",
        "            Returns two empty lists ([], []) if the customer has no purchase history in df.\n",
        "    \"\"\"\n",
        "    order_history, _ = get_customer_orders_and_products(customer_id, df)\n",
        "    if order_history.empty:\n",
        "        return [], []\n",
        "    top_categories = order_history['Category'].value_counts().index.tolist()\n",
        "    top_subcategories = order_history['Sub-Category'].value_counts().index.tolist()\n",
        "    return top_categories, top_subcategories"
      ],
      "metadata": {
        "id": "SsHMrd2VkK9y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Calculation  Functions ===\n",
        "def get_global_popular_products(top_n=5, by='Quantity'):\n",
        "    \"\"\"\n",
        "    Recommends top-N globally popular products. Sorts all products based on a specified metric ('Quantity' or 'Sales') and returns the top N. Does not consider customer history.\n",
        "\n",
        "    Args:\n",
        "        top_n (int, optional): The number of products to recommend. Defaults to 10.\n",
        "        by (str, optional): The metric to sort popularity by ('Quantity' or 'Sales'). Defaults to 'Quantity'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the top N popular products with columns ['Product ID', 'Product Name', 'Category', 'Sub-Category', <by>]. Returns an empty DataFrame if an invalid 'by' parameter is provided (though it currently raises ValueError).\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If 'by' is not 'Quantity' or 'Sales'.\n",
        "    \"\"\"\n",
        "    if by not in ['Quantity', 'Sales']:\n",
        "        raise ValueError(\"Parameter 'by' must be either 'Quantity' or 'Sales'\")\n",
        "\n",
        "    return product_popularity.sort_values(by=by, ascending=False).head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', by]]\n",
        "\n",
        "def get_content_similar_items(product_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends products similar to a given product based on content.\n",
        "\n",
        "      Uses precomputed TF-IDF vectors and cosine similarity based on product\n",
        "      name, category, and sub-category.\n",
        "\n",
        "      Args:\n",
        "          product_id (str): The ID of the product to find similar items for.\n",
        "          top_n (int, optional): The number of similar products to return.\n",
        "                                Defaults to 5.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A DataFrame containing the top_n similar products with\n",
        "                        columns ['Product Name', 'Category', 'Sub-Category'].\n",
        "                        Returns an empty DataFrame if the product_id is not found.\n",
        "      \"\"\"\n",
        "    if product_id not in product_indices.index:\n",
        "      print(f\"Product ID '{product_id}' not found in product indices.\")\n",
        "      return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    idx = product_indices[product_id]\n",
        "\n",
        "    if idx >= cosine_sim.shape[0]:\n",
        "        print(f\"Index {idx} is out of bounds for cosine similarity matrix.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get similarity scores and corresponding product indices\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Skip the first one if it's the same product (similarity = 1)\n",
        "    sim_scores = [x for x in sim_scores if x[0] != idx][:top_n]\n",
        "\n",
        "    # Build result DataFrame\n",
        "    result = []\n",
        "    for i, score in sim_scores:\n",
        "        if i >= len(products):\n",
        "            continue\n",
        "        row = products.iloc[i]\n",
        "        result.append({\n",
        "            'Product ID': row['Product ID'],\n",
        "            'Product Name': row['Product Name'],\n",
        "            'Category': row['Category'],\n",
        "            'Sub-Category': row['Sub-Category'],\n",
        "            'Similarity Score': score\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(result)\n",
        "\n",
        "def get_collaborative_similar_items(product_id, top_n=5):\n",
        "    \"\"\"Recommends products similar to a given product using item-item collaborative filtering.\n",
        "\n",
        "    Uses a precomputed product similarity matrix based on user co-purchase patterns.\n",
        "\n",
        "    Args:\n",
        "        product_id (str): The ID of the product to find collaboratively similar items for.\n",
        "        top_n (int, optional): The number of similar products to return. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the top_n similar products\n",
        "                             with columns ['Product ID', 'Similarity Score', 'Product Name',\n",
        "                             'Category', 'Sub-Category']. Returns a string message if the\n",
        "                             product_id is not found in the similarity matrix. (Consider\n",
        "                             changing string returns to an empty DataFrame).\n",
        "    \"\"\"\n",
        "\n",
        "    if product_id not in product_similarity_df.columns:\n",
        "        print(f\"Product {product_id} not found in dataset.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "    similar_scores = product_similarity_df[product_id].sort_values(ascending=False)\n",
        "    # return similar_scores[1:top_n+1]\n",
        "\n",
        "    recommended = similar_scores[1:top_n+1].reset_index()\n",
        "    recommended.columns = ['Product ID', 'Similarity Score']\n",
        "    return recommended.merge(\n",
        "        product_popularity[['Product ID', 'Product Name', 'Category', 'Sub-Category']],\n",
        "        on='Product ID', how='left'\n",
        "    )"
      ],
      "metadata": {
        "id": "upq_-CyItnj0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Main Recommendation Functions ===\n",
        "def recommend_popular(customer_id=None, top_n=5, by='Quantity'):\n",
        "    \"\"\"\n",
        "    Recommends popular products, optionally personalized for a customer.\n",
        "\n",
        "    Modes:\n",
        "    1. Global: If customer_id is None, returns globally popular products.\n",
        "    2. Unseen for Customer: Returns globally popular products not yet purchased by the customer,\n",
        "       with fallback if fewer than n are found.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str, optional): The ID of the customer. Defaults to None.\n",
        "        top_n (int, optional): The number of products to recommend. Defaults to 10.\n",
        "        by (str, optional): The metric for popularity ('Quantity' or 'Sales').\n",
        "                            Defaults to 'Quantity'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Top-N recommended products.\n",
        "\n",
        "    \"\"\"\n",
        "    if by not in ['Quantity', 'Sales']:\n",
        "        raise ValueError(\"Parameter 'by' must be either 'Quantity' or 'Sales'\")\n",
        "\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(top_n=top_n)\n",
        "\n",
        "    # Case 2: Exclude products already purchased\n",
        "    unseen_products, product_ids = get_unseen_products(customer_id, superstore_data, product_popularity)\n",
        "    unseen_products = unseen_products.sort_values(by=by, ascending=False)\n",
        "\n",
        "    # Apply fallback if needed\n",
        "    final = add_fallback_if_needed(unseen_products, product_ids, product_popularity, top_n, by)\n",
        "\n",
        "    return final.head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', by]]\n",
        "\n",
        "def recommend_content_based(customer_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends products similar to the last item purchased by a customer.\n",
        "\n",
        "    Finds the customer's most recent purchase and then uses content-based\n",
        "    similarity (get_content_similar_items) to find similar items.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the customer.\n",
        "        top_n (int, optional): The number of similar products to recommend.\n",
        "                               Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the recommended products\n",
        "                             (from get_content_similar_items) or a string message\n",
        "                             if the customer has no purchase history.\n",
        "                             (Consider changing the string return to an empty DataFrame\n",
        "                             for consistency).\n",
        "    \"\"\"\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(top_n=top_n)\n",
        "\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "          print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "          return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # Get last product bought\n",
        "    last_purchase = order_history.sort_values('Order Date', ascending=False).iloc[0]\n",
        "    last_product_id = last_purchase['Product ID']\n",
        "    last_product_name = last_purchase['Product Name']\n",
        "    print(f\"Based on last product purchased (ID: {last_product_id}): {last_product_name}\")\n",
        "\n",
        "    # Get content-based similar items\n",
        "    similar_items = get_content_similar_items(last_product_id, top_n * 2)  # get more to allow filtering\n",
        "\n",
        "    # Exclude already purchased\n",
        "    similar_items = similar_items[~similar_items['Product ID'].isin(product_ids)]\n",
        "\n",
        "    return similar_items.head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category']]\n",
        "\n",
        "def recommend_collaborative(customer_id, top_n=5):\n",
        "    \"\"\"Recommends products to a customer based on collaborative filtering.\n",
        "\n",
        "    Aggregates similarity scores from items the customer has purchased to find\n",
        "    new items that are similar based on co-purchase patterns across all users.\n",
        "    Excludes items already purchased by the customer.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the customer.\n",
        "        top_n (int, optional): The number of products to recommend. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the top_n recommended products\n",
        "                             with columns ['Product ID', 'Product Name', 'Category',\n",
        "                             'Sub-Category']. Returns a string message if the customer\n",
        "                             has no history or suitable product data isn't found.\n",
        "                             (Consider changing string returns to an empty DataFrame).\n",
        "    \"\"\"\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(top_n=top_n)\n",
        "\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "        print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # If user has multiple purchases, accumulate similarity\n",
        "    total_collab_scores = None\n",
        "    valid_count = 0\n",
        "    for pid in product_ids:\n",
        "        if pid not in product_similarity_df.columns:\n",
        "            continue\n",
        "        product_scores = product_similarity_df[pid]\n",
        "        total_collab_scores = product_scores if total_collab_scores is None else total_collab_scores + product_scores\n",
        "        valid_count += 1\n",
        "\n",
        "    if total_collab_scores is None or valid_count == 0:\n",
        "        print(f\"No valid products found for similarity for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Normalize if multiple products\n",
        "    total_collab_scores = total_collab_scores / valid_count\n",
        "\n",
        "    # Remove already purchased products\n",
        "    total_collab_scores = total_collab_scores.drop(labels=product_ids, errors='ignore')\n",
        "\n",
        "    # Get top similar product IDs\n",
        "    top_scores = total_collab_scores.sort_values(ascending=False)\n",
        "    top_ids = top_scores.head(top_n).index.tolist()\n",
        "\n",
        "    # Fetch recommended products\n",
        "    recommendations = product_popularity[product_popularity['Product ID'].isin(top_ids)].copy()\n",
        "    recommendations['Similarity Score'] = top_scores[top_ids].values\n",
        "\n",
        "    # Fallback if not enough items\n",
        "    if len(recommendations) < top_n:\n",
        "        print(f\"Only {len(recommendations)} collaborative recommendations found. Adding fallback items.\")\n",
        "        fallback = get_global_popular_products(top_n=top_n * 2)  # more to ensure enough\n",
        "        fallback = fallback[~fallback['Product ID'].isin(product_ids + top_ids)]\n",
        "        fallback = fallback.head(top_n - len(recommendations))\n",
        "        fallback['Similarity Score'] = 0  # or None, since fallback isn't similarity-based\n",
        "        recommendations = pd.concat([recommendations, fallback])\n",
        "\n",
        "    return recommendations.head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'Similarity Score']]\n",
        "\n",
        "def recommend_hybrid(customer_id, top_n=5, w_content=0.5, w_collab=0.4, w_pop=0.1, show_debug=False):\n",
        "    \"\"\"\n",
        "    Recommends products using a hybrid approach combining content similarity,\n",
        "    collaborative similarity, and global popularity.\n",
        "    \"\"\"\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(top_n=top_n)\n",
        "\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "        print(f\"No purchase history found for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --- 1. Calculate Average Content Similarity Scores ---\n",
        "    purchased_idxs_content = [product_indices[pid] for pid in product_ids if pid in product_indices]\n",
        "    if not purchased_idxs_content:\n",
        "        print(f\"No purchased products for customer '{customer_id}' found in content product index.\")\n",
        "        # Could potentially proceed without content score or return empty\n",
        "        avg_content_sim_scores = np.zeros(len(products)) # Assign zero score if no history match\n",
        "    else:\n",
        "        # Average similarity to user's purchase history\n",
        "        valid_idxs = [idx for idx in purchased_idxs_content if idx < cosine_sim.shape[0]]\n",
        "        if not valid_idxs:\n",
        "            print(f\"No valid content-based product indices for customer '{customer_id}'.\")\n",
        "            avg_content_sim_scores = np.zeros(len(products))\n",
        "        else:\n",
        "            avg_content_sim_scores = sum(cosine_sim[idx] for idx in valid_idxs) / len(valid_idxs)\n",
        "\n",
        "    content_df = pd.DataFrame({\n",
        "        'Product ID': products['Product ID'], # Use Product ID from the 'products' DataFrame\n",
        "        'content_score': avg_content_sim_scores\n",
        "    })\n",
        "\n",
        "    # --- 2. Calculate Average Collaborative Similarity Scores ---\n",
        "    total_collab_sim = None\n",
        "    valid_purchased_ids_count = 0\n",
        "    for pid in product_ids:\n",
        "        if pid not in product_similarity_df.columns:\n",
        "            continue\n",
        "        product_scores = product_similarity_df[pid]\n",
        "        total_collab_sim = product_scores if total_collab_sim is None else total_collab_sim + product_scores\n",
        "        valid_purchased_ids_count += 1\n",
        "\n",
        "    if total_collab_sim is None:\n",
        "        print(f\"No valid products found for collaborative similarity for customer '{customer_id}'.\")\n",
        "         # Assign zero score if no history match in collaborative matrix\n",
        "        collab_df = pd.DataFrame({'Product ID': product_similarity_df.columns, 'collab_score': 0.0})\n",
        "    else:\n",
        "        avg_collab_sim_scores = total_collab_sim / valid_purchased_ids_count\n",
        "        collab_df = avg_collab_sim_scores.reset_index()\n",
        "        collab_df.columns = ['Product ID', 'collab_score']\n",
        "\n",
        "    # --- 3. Combine All Scores ---\n",
        "    # Start with all products and their popularity\n",
        "    combined_df = product_popularity[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'popularity_score']].copy()\n",
        "\n",
        "    # Merge content scores\n",
        "    combined_df = combined_df.merge(content_df, on='Product ID', how='left')\n",
        "    combined_df['content_score'] = combined_df['content_score'].fillna(0)\n",
        "\n",
        "    # Merge collaborative scores\n",
        "    combined_df = combined_df.merge(collab_df, on='Product ID', how='left')\n",
        "    combined_df['collab_score'] = combined_df['collab_score'].fillna(0)\n",
        "\n",
        "    # Filter out already purchased items\n",
        "    combined_df = combined_df[~combined_df['Product ID'].isin(product_ids)].copy()\n",
        "\n",
        "    # --- 4. Normalize All Scores ---\n",
        "    # if not normalize, popularity score is just too high\n",
        "    scaler = MinMaxScaler()\n",
        "    combined_df[['content_score', 'collab_score', 'popularity_score']] = scaler.fit_transform(\n",
        "        combined_df[['content_score', 'collab_score', 'popularity_score']]\n",
        "    )\n",
        "\n",
        "    # --- 5. Calculate Final Score ---\n",
        "    combined_df['final_score'] = (\n",
        "        w_content * combined_df['content_score'] +\n",
        "        w_collab * combined_df['collab_score'] +\n",
        "        w_pop * combined_df['popularity_score']\n",
        "    )\n",
        "\n",
        "    # --- 6. Show Debug Info (Optional) ---\n",
        "    if show_debug:\n",
        "        print(\"\\n[DEBUG] Top products by each score (before final sort):\")\n",
        "        print(combined_df[['Product Name', 'content_score', 'collab_score', 'popularity_score', 'final_score']]\n",
        "              .sort_values(by='final_score', ascending=False).head(10))\n",
        "\n",
        "    # --- 7. Sort and Return ---\n",
        "    final_recommendations = combined_df.sort_values(by='final_score', ascending=False).head(top_n)\n",
        "\n",
        "    # --- 8. Fallback Logic ---\n",
        "    if len(final_recommendations) < top_n:\n",
        "      print(f\"Only {len(final_recommendations)} hybrid recommendations found. Adding fallback items.\")\n",
        "      fallback = get_global_popular_products(n=top_n * 2)\n",
        "      fallback = fallback[~fallback['Product ID'].isin(product_ids + final_recommendations['Product ID'].tolist())]\n",
        "      fallback['final_score'] = 0  # Neutral fallback score\n",
        "      final_recommendations = pd.concat([final_recommendations, fallback.head(top_n - len(final_recommendations))])\n",
        "\n",
        "    return final_recommendations[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'final_score']]"
      ],
      "metadata": {
        "id": "QNVYBKdItr0g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 5. Example Usage ==="
      ],
      "metadata": {
        "id": "hTLkJLiOity3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_recommendation_output(customer_id, num_recommendations=5):\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Example: Personalized Recommendations for One Customer\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Show context\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "\n",
        "    if order_history.empty:\n",
        "        print(f\"\\nNo purchase history found for customer '{customer_id}'. Showing global popular items instead.\")\n",
        "        print(recommend_popular(customer_id=None, top_n=num_recommendations))\n",
        "        return\n",
        "\n",
        "    print(f\"\\n Purchase History Summary for Customer: {customer_id}\")\n",
        "    print(f\"  - Total Unique Products Purchased: {len(product_ids)}\")\n",
        "\n",
        "    # Last purchase\n",
        "    last_purchase = order_history.sort_values('Order Date', ascending=False).iloc[0]\n",
        "    print(f\"  - Most Recent Purchase: '{last_purchase['Product Name']}' on {last_purchase['Order Date'].date()} — {last_purchase['Category']} / {last_purchase['Sub-Category']}\")\n",
        "\n",
        "    # Frequent items\n",
        "    freq_counts = order_history['Product ID'].value_counts()\n",
        "    top_freq_ids = freq_counts.head(3).index.tolist()\n",
        "    print(\"  - Most Frequently Purchased Items:\")\n",
        "    for pid in top_freq_ids:\n",
        "        row = superstore_data[superstore_data['Product ID'] == pid].iloc[0]\n",
        "        print(f\"    → '{row['Product Name']}' ({freq_counts[pid]} times) — {row['Category']} / {row['Sub-Category']}\")\n",
        "\n",
        "    # Category preferences\n",
        "    top_cats, top_subcats = get_customer_preferences(customer_id, superstore_data)\n",
        "    print(f\"  - Top Categories: {', '.join(top_cats[:3])}\")\n",
        "    print(f\"  - Top Sub-Categories: {', '.join(top_subcats[:3])}\")\n",
        "\n",
        "    print(\"\\n Customer Purchase History\")\n",
        "    history_sorted = order_history.sort_values('Order Date', ascending=False).copy()\n",
        "    for _, row in history_sorted.iterrows():\n",
        "        print(f\"  [{row['Order Date'].date()}] {row['Product Name']} (ID: {row['Product ID']}) — {row['Category']} / {row['Sub-Category']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\" Recommendation Outputs\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    def explain_recommendations(name, df, context_col=None):\n",
        "        print(f\"\\nTop {num_recommendations} {name} Recommendations:\")\n",
        "        if context_col:\n",
        "            print(f\"(Based on {context_col})\")\n",
        "        for _, row in df.iterrows():\n",
        "            reason = []\n",
        "            if 'Similarity Score' in row and row['Similarity Score'] == 0:\n",
        "                reason.append(\"fallback (popular item)\")\n",
        "            elif 'Similarity Score' in row:\n",
        "                reason.append(f\"similarity score: {row['Similarity Score']:.4f}\")\n",
        "            if row['Category'] in top_cats:\n",
        "                reason.append(f\"matches favorite category: {row['Category']}\")\n",
        "            if row['Sub-Category'] in top_subcats:\n",
        "                reason.append(f\"matches frequent sub-category: {row['Sub-Category']}\")\n",
        "            explanation = \"; \".join(reason)\n",
        "            print(f\"→ {row['Product Name']} (ID: {row['Product ID']}) — {row['Category']} / {row['Sub-Category']}\")\n",
        "            if explanation:\n",
        "                print(f\"   Explanation: {explanation}\\n\")\n",
        "\n",
        "    # Generate all recommendations\n",
        "    popular_df = recommend_popular(customer_id, top_n=num_recommendations)\n",
        "    content_df = recommend_content_based(customer_id, top_n=num_recommendations)\n",
        "    collab_df = recommend_collaborative(customer_id, top_n=num_recommendations)\n",
        "    hybrid_df = recommend_hybrid(customer_id, top_n=num_recommendations, show_debug=True)\n",
        "\n",
        "    # Print all with explanations\n",
        "    explain_recommendations(\"Popular\", popular_df, context_col=\"overall purchase frequency across all users\")\n",
        "    explain_recommendations(\"Content-Based\", content_df, context_col=\"last product purchased\")\n",
        "    explain_recommendations(\"Collaborative\", collab_df, context_col=\"co-purchase patterns of similar users\")\n",
        "    explain_recommendations(\"Hybrid\", hybrid_df, context_col=\"content + collaborative + popularity\")\n",
        "\n",
        "# Example usage:\n",
        "print_recommendation_output(\"WB-21850\", num_recommendations=5)\n"
      ],
      "metadata": {
        "id": "IWmSoeATiZYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e371268-4895-4df7-f7c8-74c3676d3b4d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Example: Personalized Recommendations for One Customer\n",
            "============================================================\n",
            "\n",
            " Purchase History Summary for Customer: WB-21850\n",
            "  - Total Unique Products Purchased: 36\n",
            "  - Most Recent Purchase: 'Contract Clock, 14\", Brown' on 2017-12-10 — Furniture / Furnishings\n",
            "  - Most Frequently Purchased Items:\n",
            "    → 'Fellowes 8 Outlet Superior Workstation Surge Protector' (2 times) — Office Supplies / Appliances\n",
            "    → 'Fellowes PB200 Plastic Comb Binding Machine' (1 times) — Office Supplies / Binders\n",
            "    → 'Motorla HX550 Universal Bluetooth Headset' (1 times) — Technology / Phones\n",
            "  - Top Categories: Office Supplies, Technology, Furniture\n",
            "  - Top Sub-Categories: Binders, Phones, Furnishings\n",
            "\n",
            " Customer Purchase History\n",
            "  [2017-12-10] Contract Clock, 14\", Brown (ID: FUR-FU-10001475) — Furniture / Furnishings\n",
            "  [2017-12-10] Heavy-Duty E-Z-D Binders (ID: OFF-BI-10000014) — Office Supplies / Binders\n",
            "  [2017-11-11] Vinyl Coated Wire Paper Clips in Organizer Box, 800/Box (ID: OFF-FA-10004854) — Office Supplies / Fasteners\n",
            "  [2017-06-29] GBC DocuBind TL200 Manual Binding Machine (ID: OFF-BI-10003091) — Office Supplies / Binders\n",
            "  [2017-06-29] Enermax Briskie RF Wireless Keyboard and Mouse Combo (ID: TEC-AC-10001284) — Technology / Accessories\n",
            "  [2017-06-29] Newell 328 (ID: OFF-AR-10000255) — Office Supplies / Art\n",
            "  [2017-06-29] Trav-L-File Heavy-Duty Shuttle II, Black (ID: OFF-ST-10002974) — Office Supplies / Storage\n",
            "  [2016-12-11] Rogers Profile Extra Capacity Storage Tub (ID: OFF-ST-10000636) — Office Supplies / Storage\n",
            "  [2016-12-11] IBM Multi-Purpose Copy Paper, 8 1/2 x 11\", Case (ID: OFF-PA-10000241) — Office Supplies / Paper\n",
            "  [2016-12-11] Microsoft Natural Ergonomic Keyboard 4000 (ID: TEC-AC-10000057) — Technology / Accessories\n",
            "  [2016-12-11] Global Wood Trimmed Manager's Task Chair, Khaki (ID: FUR-CH-10003774) — Furniture / Chairs\n",
            "  [2016-12-11] Recycled Easel Ring Binders (ID: OFF-BI-10002824) — Office Supplies / Binders\n",
            "  [2016-12-11] GBC Recycled VeloBinder Covers (ID: OFF-BI-10004001) — Office Supplies / Binders\n",
            "  [2016-12-11] Ibico Laser Imprintable Binding System Covers (ID: OFF-BI-10004593) — Office Supplies / Binders\n",
            "  [2016-12-11] Hon Non-Folding Utility Tables (ID: FUR-TA-10004619) — Furniture / Tables\n",
            "  [2016-12-11] Boston 16765 Mini Stand Up Battery Pencil Sharpener (ID: OFF-AR-10000914) — Office Supplies / Art\n",
            "  [2016-12-11] Fellowes 8 Outlet Superior Workstation Surge Protector (ID: OFF-AP-10001469) — Office Supplies / Appliances\n",
            "  [2016-12-11] Black Avery Memo-Size 3-Ring Binder, 5 1/2\" x 8 1/2\" (ID: OFF-BI-10002897) — Office Supplies / Binders\n",
            "  [2016-10-10] Eldon 400 Class Desk Accessories, Black Carbon (ID: FUR-FU-10004963) — Furniture / Furnishings\n",
            "  [2016-10-10] Wilson Jones Ledger-Size, Piano-Hinge Binder, 2\", Blue (ID: OFF-BI-10001597) — Office Supplies / Binders\n",
            "  [2016-01-15] Square Ring Data Binders, Rigid 75 Pt. Covers, 11\" x 14-7/8\" (ID: OFF-BI-10002225) — Office Supplies / Binders\n",
            "  [2016-01-15] Xerox 1959 (ID: OFF-PA-10004285) — Office Supplies / Paper\n",
            "  [2016-01-15] #10 Gummed Flap White Envelopes, 100/Box (ID: OFF-EN-10001137) — Office Supplies / Envelopes\n",
            "  [2015-11-30] Fellowes PB200 Plastic Comb Binding Machine (ID: OFF-BI-10003656) — Office Supplies / Binders\n",
            "  [2015-11-30] Revere Boxed Rubber Bands by Revere (ID: OFF-FA-10000053) — Office Supplies / Fasteners\n",
            "  [2015-11-30] Motorla HX550 Universal Bluetooth Headset (ID: TEC-PH-10002807) — Technology / Phones\n",
            "  [2015-08-10] Fellowes 8 Outlet Superior Workstation Surge Protector (ID: OFF-AP-10001469) — Office Supplies / Appliances\n",
            "  [2015-08-10] OtterBox Commuter Series Case - Samsung Galaxy S4 (ID: TEC-PH-10004188) — Technology / Phones\n",
            "  [2015-08-10] AT&T 1080 Corded phone (ID: TEC-PH-10000576) — Technology / Phones\n",
            "  [2014-12-20] Belkin Premiere Surge Master II 8-outlet surge protector (ID: OFF-AP-10001563) — Office Supplies / Appliances\n",
            "  [2014-12-20] Logitech Desktop MK120 Mouse and keyboard Combo (ID: TEC-AC-10004510) — Technology / Accessories\n",
            "  [2014-12-12] Eldon Advantage Chair Mats for Low to Medium Pile Carpets (ID: FUR-FU-10003975) — Furniture / Furnishings\n",
            "  [2014-11-04] Hewlett-Packard Deskjet D4360 Printer (ID: TEC-MA-10003246) — Technology / Machines\n",
            "  [2014-11-04] Xerox 2000 (ID: OFF-PA-10000223) — Office Supplies / Paper\n",
            "  [2014-11-04] Cardinal EasyOpen D-Ring Binders (ID: OFF-BI-10001036) — Office Supplies / Binders\n",
            "  [2014-11-04] Bevis Round Conference Table Top, X-Base (ID: FUR-TA-10002041) — Furniture / Tables\n",
            "  [2014-11-04] Polycom SoundPoint Pro SE-225 Corded phone (ID: TEC-PH-10001079) — Technology / Phones\n",
            "\n",
            "============================================================\n",
            " Recommendation Outputs\n",
            "============================================================\n",
            "\n",
            "[DEBUG] Top products by each score (before final sort):\n",
            "                                          Product Name  content_score  collab_score  popularity_score  final_score\n",
            "702                    Wilson Jones Active Use Binders       0.577093      0.939828          0.270270     0.691505\n",
            "658                              Avery Durable Binders       0.768185      0.449049          0.662162     0.629928\n",
            "721                            Avery Arch Ring Binders       0.778253      0.341351          0.851351     0.610802\n",
            "643                         Zipper Ring Binder Pockets       0.560541      0.633911          0.581081     0.591943\n",
            "752                  Ibico Standard Transparent Covers       0.532281      0.672576          0.445946     0.579766\n",
            "843                                 Round Ring Binders       1.000000      0.088590          0.364865     0.571922\n",
            "764                     GBC Plasticlear Binding Covers       0.665290      0.518078          0.297297     0.569606\n",
            "708                     Trimflex Flexible Post Binders       0.529805      0.683982          0.270270     0.565522\n",
            "801    Wilson Jones International Size A4 Ring Binders       0.649087      0.522614          0.229730     0.556562\n",
            "641  Avery Non-Stick Heavy Duty View Round Locking ...       0.716328      0.455507          0.148649     0.555231\n",
            "\n",
            "Top 5 Popular Recommendations:\n",
            "(Based on overall purchase frequency across all users)\n",
            "→ Logitech P710e Mobile Speakerphone (ID: TEC-AC-10003832) — Technology / Accessories\n",
            "   Explanation: matches favorite category: Technology; matches frequent sub-category: Accessories\n",
            "\n",
            "→ Xerox 1881 (ID: OFF-PA-10001970) — Office Supplies / Paper\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Paper\n",
            "\n",
            "→ GBC Premium Transparent Covers with Diagonal Lined Pattern (ID: OFF-BI-10001524) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Avery Arch Ring Binders (ID: OFF-BI-10002026) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Situations Contoured Folding Chairs, 4/Set (ID: FUR-CH-10002647) — Furniture / Chairs\n",
            "   Explanation: matches favorite category: Furniture; matches frequent sub-category: Chairs\n",
            "\n",
            "\n",
            "Top 5 Content-Based Recommendations:\n",
            "(Based on last product purchased)\n",
            "→ AT&T 1080 Phone (ID: TEC-PH-10004120) — Technology / Phones\n",
            "   Explanation: similarity score: 0.8492; matches favorite category: Technology; matches frequent sub-category: Phones\n",
            "\n",
            "→ #6 3/4 Gummed Flap White Envelopes (ID: OFF-EN-10003068) — Office Supplies / Envelopes\n",
            "   Explanation: similarity score: 0.8432; matches favorite category: Office Supplies; matches frequent sub-category: Envelopes\n",
            "\n",
            "→ Eldon Advantage Foldable Chair Mats for Low Pile Carpets (ID: FUR-FU-10004622) — Furniture / Furnishings\n",
            "   Explanation: similarity score: 0.8373; matches favorite category: Furniture; matches frequent sub-category: Furnishings\n",
            "\n",
            "→ Eldon Antistatic Chair Mats for Low to Medium Pile Carpets (ID: FUR-FU-10000293) — Furniture / Furnishings\n",
            "   Explanation: similarity score: 0.8363; matches favorite category: Furniture; matches frequent sub-category: Furnishings\n",
            "\n",
            "→ OtterBox Defender Series Case - Samsung Galaxy S4 (ID: TEC-PH-10002564) — Technology / Phones\n",
            "   Explanation: similarity score: 0.8044; matches favorite category: Technology; matches frequent sub-category: Phones\n",
            "\n",
            "\n",
            "Top 5 Collaborative Recommendations:\n",
            "(Based on co-purchase patterns of similar users)\n",
            "→ Floodlight Indoor Halogen Bulbs, 1 Bulb per Pack, 60 Watts (ID: FUR-FU-10001861) — Furniture / Furnishings\n",
            "   Explanation: similarity score: 0.0378; matches favorite category: Furniture; matches frequent sub-category: Furnishings\n",
            "\n",
            "→ G.E. Halogen Desk Lamp Bulbs (ID: FUR-FU-10002191) — Furniture / Furnishings\n",
            "   Explanation: similarity score: 0.0363; matches favorite category: Furniture; matches frequent sub-category: Furnishings\n",
            "\n",
            "→ Manco Dry-Lighter Erasable Highlighter (ID: OFF-AR-10000817) — Office Supplies / Art\n",
            "   Explanation: similarity score: 0.0355; matches favorite category: Office Supplies; matches frequent sub-category: Art\n",
            "\n",
            "→ Wilson Jones Active Use Binders (ID: OFF-BI-10001634) — Office Supplies / Binders\n",
            "   Explanation: similarity score: 0.0341; matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Zebra GK420t Direct Thermal/Thermal Transfer Printer (ID: TEC-MA-10001695) — Technology / Machines\n",
            "   Explanation: similarity score: 0.0313; matches favorite category: Technology; matches frequent sub-category: Machines\n",
            "\n",
            "\n",
            "Top 5 Hybrid Recommendations:\n",
            "(Based on content + collaborative + popularity)\n",
            "→ Wilson Jones Active Use Binders (ID: OFF-BI-10001634) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Avery Durable Binders (ID: OFF-BI-10000546) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Avery Arch Ring Binders (ID: OFF-BI-10002026) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Zipper Ring Binder Pockets (ID: OFF-BI-10000145) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Ibico Standard Transparent Covers (ID: OFF-BI-10002852) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 6. Evaluation (Can't think of it yet) ==="
      ],
      "metadata": {
        "id": "2E4GVpqP1G95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_at_k(recommended, actual_set, k):\n",
        "    if not recommended:\n",
        "        return 0.0\n",
        "    hits = sum(1 for item in recommended[:k] if item in actual_set)\n",
        "    return hits / k\n",
        "\n",
        "def recall_at_k(recommended, actual_set, k):\n",
        "    if not actual_set:\n",
        "        return 0.0\n",
        "    hits = sum(1 for item in recommended[:k] if item in actual_set)\n",
        "    return hits / len(actual_set)\n",
        "\n",
        "def evaluate_model(model_func, k=10, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Evaluates a recommendation model using Precision@K and Recall@K.\n",
        "\n",
        "    Args:\n",
        "        model_func (function): Recommender function with signature model_func(customer_id, top_n)\n",
        "        k (int): Top-K cutoff\n",
        "        model_name (str): Label for printing results\n",
        "\n",
        "    Returns:\n",
        "        None. Prints out average metrics.\n",
        "    \"\"\"\n",
        "    precisions, recalls = [], []\n",
        "\n",
        "    for user_id in test_user_items:\n",
        "        try:\n",
        "            recs = model_func(user_id, top_n=k)\n",
        "            rec_items = recs['Product ID'].tolist() if not recs.empty else []\n",
        "        except Exception as e:\n",
        "            print(f\"Error for user {user_id} in {model_name}: {e}\")\n",
        "            rec_items = []\n",
        "\n",
        "        actual_items = test_user_items[user_id]\n",
        "        precisions.append(precision_at_k(rec_items, actual_items, k))\n",
        "        recalls.append(recall_at_k(rec_items, actual_items, k))\n",
        "\n",
        "    avg_precision = sum(precisions) / len(precisions)\n",
        "    avg_recall = sum(recalls) / len(recalls)\n",
        "\n",
        "    print(f\"\\n📊 Evaluation for {model_name}\")\n",
        "    print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
        "    print(f\"Recall@{k}: {avg_recall:.4f}\")\n"
      ],
      "metadata": {
        "id": "zSMtSxJO1JlD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(recommend_popular, model_name=\"Popularity-Based\")\n",
        "evaluate_model(recommend_content_based, model_name=\"Content-Based\")\n",
        "evaluate_model(recommend_collaborative, model_name=\"Collaborative Filtering\")\n",
        "evaluate_model(recommend_hybrid, model_name=\"Hybrid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "5bhwmnwp1P3S",
        "outputId": "f9700e7e-99ee-4ed3-ccd2-17882f614096"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Evaluation for Popularity-Based\n",
            "Precision@10: 0.0000\n",
            "Recall@10: 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-de5f4ed18d72>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommend_popular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Popularity-Based\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommend_content_based\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Content-Based\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommend_collaborative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Collaborative Filtering\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommend_hybrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Hybrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e1904ea8a0b8>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_func, k, model_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_user_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mrec_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Product ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-4786a1576bfb>\u001b[0m in \u001b[0;36mrecommend_content_based\u001b[0;34m(customer_id, top_n)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Aggregate by Product ID — sum or average scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0maggregated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Product ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Product Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Category'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sub-Category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Similarity Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Sort and return top_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m             )\n\u001b[1;32m   2451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2452\u001b[0;31m             result = self._cython_agg_general(\n\u001b[0m\u001b[1;32m   2453\u001b[0m                 \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2454\u001b[0m                 \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"idxmin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"idxmax\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36mgrouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrouped_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36marray_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0marray_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m                 result = self._grouper._cython_operation(\n\u001b[0m\u001b[1;32m   1974\u001b[0m                     \u001b[0;34m\"aggregate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"aggregate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mcy_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWrappedCythonOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_dropped_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_dropped_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mhas_dropped_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mWhether\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mnull\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdropped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \"\"\"\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mgroup_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgroup_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mcomp_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_group_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_compressed_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_group_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;31m# The first returned ndarray may have any signed integer dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m             \u001b[0mgroup_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompress_group_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;31m# FIXME: compress_group_index's second return value is int64, not intp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36mget_group_index\u001b[0;34m(labels, shape, sort, xnull)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# compute flat ids for the first `nlev` levels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnlev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"i8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3189\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3190\u001b[0m     \"\"\"\n\u001b[0;32m-> 3191\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3192\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}