{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nancy-kataria/NexTrade/blob/main/product_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== Imports ==="
      ],
      "metadata": {
        "id": "TxLsn_3YgSds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FQjFG7BkiGKB"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 1. Dataset Download ==="
      ],
      "metadata": {
        "id": "BitMW-zx-j2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "print(\"Dowlaod Dataset...\")\n",
        "path = kagglehub.dataset_download(\"vivek468/superstore-dataset-final\")\n",
        "print(f\"Dataset downloaded to: {path}\")\n",
        "csv_file_path = os.path.join(path, \"Sample - Superstore.csv\")\n",
        "print(f\"Reading data from: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "xj6z5B1j-nv7",
        "outputId": "18397680-ac7a-4ade-f3e0-9f427fe5f078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dowlaod Dataset...\n",
            "Dataset downloaded to: /kaggle/input/superstore-dataset-final\n",
            "Reading data from: /kaggle/input/superstore-dataset-final/Sample - Superstore.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 2. Load & Clean Data ==="
      ],
      "metadata": {
        "id": "0fos8cod7pJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    superstore_data = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {csv_file_path}.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "Mh4kbf0HjNH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b17c9b-3b2b-4ff8-9127-56e91c3fe581"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep necessary columns\n",
        "columns_to_keep = ['Order ID', 'Order Date', 'Ship Date', 'Customer ID', 'Country', 'City', 'State', 'Postal Code', 'Product ID', 'Product Name', 'Sales', 'Quantity', 'Category', 'Sub-Category']\n",
        "superstore_data = superstore_data[columns_to_keep]"
      ],
      "metadata": {
        "id": "_fTuhoxWlcUH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows to check the data\n",
        "print(\"First 5 rows of data:\")\n",
        "print(superstore_data.head())"
      ],
      "metadata": {
        "id": "4bSD5nfglcFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dates\n",
        "superstore_data['Order Date'] = pd.to_datetime(superstore_data['Order Date'])\n",
        "superstore_data['Ship Date'] = pd.to_datetime(superstore_data['Ship Date'])"
      ],
      "metadata": {
        "id": "v8JDsd7ZkKAk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop rows with missing any necessary columns\n",
        "superstore_data.dropna(subset=columns_to_keep, inplace=True)"
      ],
      "metadata": {
        "id": "omwT_AcdkKXc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Finding Customers with Most Transactions ---\")\n",
        "\n",
        "# Count the number of rows (transaction line items) for each Customer ID\n",
        "customer_transaction_counts = superstore_data.groupby('Customer ID').size()\n",
        "\n",
        "# Sort the counts in descending order\n",
        "customer_transaction_counts_sorted = customer_transaction_counts.sort_values(ascending=False)\n",
        "\n",
        "# Display the top, e.g., 10 customers\n",
        "print(\"Top 10 Customers by Number of Transaction Entries:\")\n",
        "print(customer_transaction_counts_sorted.head(10))\n",
        "\n",
        "# Get the Customer ID with the absolute highest count\n",
        "if not customer_transaction_counts_sorted.empty:\n",
        "    top_customer_id = customer_transaction_counts_sorted.index[0]\n",
        "    top_customer_count = customer_transaction_counts_sorted.iloc[0]\n",
        "    print(f\"\\nCustomer with the most transaction entries: '{top_customer_id}' ({top_customer_count} entries)\")\n",
        "else:\n",
        "    top_customer_id = None # Handle case where data might be empty\n",
        "    print(\"\\nCould not determine top customer.\")\n",
        "\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCw9orMdu8YU",
        "outputId": "a8fa2254-696b-4012-eb0c-6f78be6976bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Finding Customers with Most Transactions ---\n",
            "Top 10 Customers by Number of Transaction Entries:\n",
            "Customer ID\n",
            "WB-21850    37\n",
            "MA-17560    34\n",
            "JL-15835    34\n",
            "PP-18955    34\n",
            "EH-13765    32\n",
            "JD-15895    32\n",
            "SV-20365    32\n",
            "CK-12205    32\n",
            "AP-10915    31\n",
            "EP-13915    31\n",
            "dtype: int64\n",
            "\n",
            "Customer with the most transaction entries: 'WB-21850' (37 entries)\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== (TEST STAGE) 2b. Evaluation Split (Time-Based) ==="
      ],
      "metadata": {
        "id": "n-pBRT2gpfWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Splitting Data for Evaluation ---\")\n",
        "# Sort data by order date\n",
        "superstore_data_sorted = superstore_data.sort_values('Order Date').copy()\n",
        "superstore_data_sorted.reset_index(drop=True, inplace=True) # Optional: Reset index\n",
        "\n",
        "# Define split point (e.g., 80% train, 20% test based on row count after sorting)\n",
        "# Alternatively, pick a specific date for splitting\n",
        "split_index = int(len(superstore_data_sorted) * 0.8)\n",
        "train_df = superstore_data_sorted.iloc[:split_index].copy()\n",
        "test_df = superstore_data_sorted.iloc[split_index:].copy()\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Testing data shape: {test_df.shape}\")\n",
        "if not train_df.empty:\n",
        "    print(f\"Training data period: {train_df['Order Date'].min()} to {train_df['Order Date'].max()}\")\n",
        "if not test_df.empty:\n",
        "    print(f\"Testing data period: {test_df['Order Date'].min()} to {test_df['Order Date'].max()}\")\n",
        "\n",
        "# Identify users present in the test set for evaluation\n",
        "test_users = test_df['Customer ID'].unique()\n",
        "print(f\"Number of unique users in test set: {len(test_users)}\")"
      ],
      "metadata": {
        "id": "0wNF5fG4pj3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 3. Precomputation  ==="
      ],
      "metadata": {
        "id": "go59KyXFg9VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Product Popularity\n",
        "product_popularity = superstore_data.groupby('Product ID').agg({\n",
        "    'Product Name': 'first',\n",
        "    'Category': 'first',\n",
        "    'Sub-Category': 'first',\n",
        "    'Quantity': 'sum',\n",
        "    'Sales': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Normalize popularity score\n",
        "product_popularity['popularity_score'] = product_popularity['Quantity'] / product_popularity['Quantity'].max()\n",
        "\n",
        "# 2. Content-Based Info Preparation\n",
        "superstore_data['product_info'] = (\n",
        "    superstore_data['Product Name'].astype(str) + ' ' +\n",
        "    superstore_data['Category'].astype(str) + ' ' +\n",
        "    superstore_data['Sub-Category'].astype(str)\n",
        ")\n",
        "\n",
        "# One row per product\n",
        "products = superstore_data.drop_duplicates(subset='Product ID')[\n",
        "    ['Product ID', 'Product Name', 'Category', 'Sub-Category', 'product_info']\n",
        "]\n",
        "\n",
        "# 3. TF-IDF Matrix and Cosine Similarity\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(products['product_info'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 4. Product Index Mapping\n",
        "product_indices = pd.Series(products.index, index=products['Product ID']).drop_duplicates()\n",
        "\n",
        "# 5. User-Product Matrix and Product Similarity for Collaborative Filtering\n",
        "user_product_matrix = superstore_data.pivot_table(\n",
        "    index='Customer ID',\n",
        "    columns='Product ID',\n",
        "    values='Quantity',\n",
        "    aggfunc='sum'\n",
        ").fillna(0)\n",
        "\n",
        "product_similarity = cosine_similarity(user_product_matrix.T)\n",
        "product_similarity_df = pd.DataFrame(\n",
        "    product_similarity,\n",
        "    index=user_product_matrix.columns,\n",
        "    columns=user_product_matrix.columns\n",
        ")"
      ],
      "metadata": {
        "id": "c9fGWIFgg_Mp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 4. Recommendation Functions ==="
      ],
      "metadata": {
        "id": "M0vdvNDY7zWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Helper Functions ===\n",
        "def get_customer_data(customer_id, df):\n",
        "    \"\"\"Fetches purchase data and unique purchased product IDs for a customer.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the target customer.\n",
        "        df (pd.DataFrame): The main DataFrame containing all transaction data.\n",
        "                           Must include 'Customer ID' and 'Product ID'.\n",
        "\n",
        "    Returns:\n",
        "        tuple[pd.DataFrame, np.ndarray]: A tuple containing:\n",
        "            - customer_data (pd.DataFrame): A DataFrame filtered to only include\n",
        "                                            rows for the given customer_id. Returns\n",
        "                                            an empty DataFrame if customer not found.\n",
        "            - purchased_ids (np.ndarray): A NumPy array of unique Product IDs\n",
        "                                          purchased by the customer. Returns an\n",
        "                                          empty array if customer not found.\n",
        "    \"\"\"\n",
        "    customer_data = df[df['Customer ID'] == customer_id].copy()\n",
        "    # Using .copy() is good practice here to prevent potential SettingWithCopyWarning\n",
        "    # if the returned DataFrame is modified later in another function.\n",
        "    purchased_ids = customer_data['Product ID'].unique()\n",
        "    return customer_data, purchased_ids\n",
        "\n",
        "def get_unseen_products(customer_id, df, product_df):\n",
        "    \"\"\"\n",
        "    Get a list of products the customer hasn't purchased yet\n",
        "\n",
        "    Args:\n",
        "      customer_id (str): ID of the target customer.\n",
        "      df (pd.DataFrame): Full transaction data (e.g., superstore_data)\n",
        "                           used to find customer history.\n",
        "      product_df (pd.DataFrame): DataFrame of all products to recommend\n",
        "                                   from (e.g., product_popularity).\n",
        "\n",
        "    Returns:\n",
        "      pd.DataFrame: filtered product_df with only unseen products\n",
        "      pd.DataFrame: list of purchased Product IDs for fallback logic\n",
        "    \"\"\"\n",
        "\n",
        "    _, purchased_ids = get_customer_data(customer_id, df)\n",
        "    return product_df[~product_df['Product ID'].isin(purchased_ids)], purchased_ids\n",
        "\n",
        "def add_fallback_if_needed(recommendations, purchased, product_df, n, by):\n",
        "    \"\"\"\n",
        "    Add fallback recommendations if there aren't enough unseen products to recommend\n",
        "    This uses globally popular products (based on 'Quantity' or 'Sales') to fill the gap\n",
        "\n",
        "    Args:\n",
        "      recommendations: filtered list of unseen, ranked products\n",
        "      purchased: list of already purchased product IDs\n",
        "      product_df: global product list (e.g., product_popularity)\n",
        "      n: number of products we want to recommend\n",
        "      by: popularity metric ('Quantity' or 'Sales')\n",
        "\n",
        "    Returns:\n",
        "     pd.DataFrame: final DataFrame of n recommendations\n",
        "    \"\"\"\n",
        "\n",
        "    if len(recommendations) < n:\n",
        "        print(f\"Customer has only {len(recommendations)} new products available. Showing global popular items instead.\")\n",
        "        fallback = get_global_popular_products(n=n, by=by)\n",
        "        fallback = fallback[~fallback['Product ID'].isin(purchased)]\n",
        "        recommendations = pd.concat([recommendations, fallback]).drop_duplicates('Product ID')\n",
        "    return recommendations\n",
        "\n",
        "def get_customer_preferences(customer_id, df):\n",
        "    \"\"\"\n",
        "    Gets the customer's most frequent categories and sub-categories.\n",
        "\n",
        "    Analyzes a customer's purchase history to find the categories and\n",
        "    sub-categories they interact with most often, based on the count\n",
        "    of purchases in each. Used for personalized popularity recommendations.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the target customer.\n",
        "        df (pd.DataFrame): The DataFrame containing transaction data, including\n",
        "                           'Customer ID', 'Category', and 'Sub-Category' columns.\n",
        "\n",
        "    Returns:\n",
        "        tuple[list[str], list[str]]: A tuple containing two lists:\n",
        "            - The first list contains category names, sorted by frequency (most frequent first).\n",
        "            - The second list contains sub-category names, sorted by frequency.\n",
        "            Returns two empty lists ([], []) if the customer has no purchase history in df.\n",
        "    \"\"\"\n",
        "    customer_data, _ = get_customer_data(customer_id, df)\n",
        "    if customer_data.empty:\n",
        "        return [], []\n",
        "    top_categories = customer_data['Category'].value_counts().index.tolist()\n",
        "    top_subcategories = customer_data['Sub-Category'].value_counts().index.tolist()\n",
        "    return top_categories, top_subcategories\n",
        "\n",
        "\n",
        "\n",
        "# === Calculation  Functions ===\n",
        "def get_global_popular_products(n=10, by='Quantity'):\n",
        "    \"\"\"\n",
        "    Recommends top-N globally popular products. Sorts all products based on a specified metric ('Quantity' or 'Sales') and returns the top N. Does not consider customer history.\n",
        "\n",
        "    Args:\n",
        "        n (int, optional): The number of products to recommend. Defaults to 10.\n",
        "        by (str, optional): The metric to sort popularity by ('Quantity' or 'Sales'). Defaults to 'Quantity'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the top N popular products with columns ['Product ID', 'Product Name', 'Category', 'Sub-Category', <by>]. Returns an empty DataFrame if an invalid 'by' parameter is provided (though it currently raises ValueError).\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If 'by' is not 'Quantity' or 'Sales'.\n",
        "    \"\"\"\n",
        "    if by not in ['Quantity', 'Sales']:\n",
        "        raise ValueError(\"Parameter 'by' must be either 'Quantity' or 'Sales'\")\n",
        "\n",
        "    return product_popularity.sort_values(by=by, ascending=False).head(n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', by]]\n",
        "\n",
        "def get_content_similar_items(product_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends products similar to a given product based on content.\n",
        "\n",
        "      Uses precomputed TF-IDF vectors and cosine similarity based on product\n",
        "      name, category, and sub-category.\n",
        "\n",
        "      Args:\n",
        "          product_id (str): The ID of the product to find similar items for.\n",
        "          top_n (int, optional): The number of similar products to return.\n",
        "                                Defaults to 5.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A DataFrame containing the top_n similar products with\n",
        "                        columns ['Product Name', 'Category', 'Sub-Category'].\n",
        "                        Returns an empty DataFrame if the product_id is not found.\n",
        "      \"\"\"\n",
        "    if product_id not in product_indices.index:\n",
        "      print(f\"Product ID '{product_id}' not found in product indices.\")\n",
        "      return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    idx = product_indices[product_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "    product_idxs = [i[0] for i in sim_scores]\n",
        "\n",
        "    return products.iloc[product_idxs][['Product Name', 'Category', 'Sub-Category']]\n",
        "\n",
        "def get_collaborative_similar_items(product_id, top_n=5):\n",
        "    \"\"\"Recommends products similar to a given product using item-item collaborative filtering.\n",
        "\n",
        "    Uses a precomputed product similarity matrix based on user co-purchase patterns.\n",
        "\n",
        "    Args:\n",
        "        product_id (str): The ID of the product to find collaboratively similar items for.\n",
        "        top_n (int, optional): The number of similar products to return. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the top_n similar products\n",
        "                             with columns ['Product ID', 'Similarity Score', 'Product Name',\n",
        "                             'Category', 'Sub-Category']. Returns a string message if the\n",
        "                             product_id is not found in the similarity matrix. (Consider\n",
        "                             changing string returns to an empty DataFrame).\n",
        "    \"\"\"\n",
        "\n",
        "    if product_id not in product_similarity_df.columns:\n",
        "        print(f\"Product {product_id} not found in dataset.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "    similar_scores = product_similarity_df[product_id].sort_values(ascending=False)\n",
        "    # return similar_scores[1:top_n+1]\n",
        "\n",
        "    recommended = similar_scores[1:top_n+1].reset_index()\n",
        "    recommended.columns = ['Product ID', 'Similarity Score']\n",
        "    return recommended.merge(\n",
        "        product_popularity[['Product ID', 'Product Name', 'Category', 'Sub-Category']],\n",
        "        on='Product ID', how='left'\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# === Main Recommendation Functions ===\n",
        "def recommend_popular(customer_id=None, personalized=False, n=10, by='Quantity'):\n",
        "    \"\"\"Recommends popular products, optionally personalized for a customer.\n",
        "\n",
        "    Modes:\n",
        "    1. Global: If customer_id is None, returns globally popular products.\n",
        "    2. Unseen for Customer: If customer_id is provided and personalized=False,\n",
        "       returns globally popular products not yet purchased by the customer.\n",
        "    3. Personalized Popular: If customer_id is provided and personalized=True,\n",
        "       returns popular products from the customer's preferred categories/sub-categories\n",
        "       that they haven't purchased yet.\n",
        "\n",
        "    Includes fallback to global popular items if not enough personalized/unseen\n",
        "    items are found.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str, optional): The ID of the customer. Defaults to None.\n",
        "        personalized (bool, optional): Whether to filter by customer preferences.\n",
        "                                       Defaults to False. Ignored if customer_id is None.\n",
        "        n (int, optional): The number of products to recommend. Defaults to 10.\n",
        "        by (str, optional): The metric for popularity ('Quantity' or 'Sales').\n",
        "                            Defaults to 'Quantity'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the recommended products with columns\n",
        "                      ['Product ID', 'Product Name', 'Category', 'Sub-Category', <metric_used>].\n",
        "                      Returns global recommendations if customer preferences cannot be determined.\n",
        "                      May return fewer than n items if insufficient products are available\n",
        "                      even after fallback.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If 'by' is not 'Quantity' or 'Sales'.\n",
        "    \"\"\"\n",
        "    if by not in ['Quantity', 'Sales']:\n",
        "        raise ValueError(\"Parameter 'by' must be either 'Quantity' or 'Sales'\")\n",
        "\n",
        "    if customer_id is None:\n",
        "        return get_global_popular_products(n, by)\n",
        "\n",
        "    df = product_popularity\n",
        "\n",
        "    if personalized:\n",
        "        top_cats, top_subcats = get_customer_preferences(customer_id, superstore_data)\n",
        "        if not top_cats or not top_subcats:\n",
        "            print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "            return get_global_popular_products(n, by)\n",
        "        df = df[(df['Category'].isin(top_cats)) | (df['Sub-Category'].isin(top_subcats))]\n",
        "\n",
        "    unseen, purchased = get_unseen_products(customer_id, superstore_data, df)\n",
        "    unseen = unseen.sort_values(by=by, ascending=False)\n",
        "    final = add_fallback_if_needed(unseen, purchased, product_popularity, n, by)\n",
        "\n",
        "    return final.head(n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', by]]\n",
        "\n",
        "def recommend_content_based(customer_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends products similar to the last item purchased by a customer.\n",
        "\n",
        "    Finds the customer's most recent purchase and then uses content-based\n",
        "    similarity (get_content_similar_items) to find similar items.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the customer.\n",
        "        top_n (int, optional): The number of similar products to recommend.\n",
        "                               Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the recommended products\n",
        "                             (from get_content_similar_items) or a string message\n",
        "                             if the customer has no purchase history.\n",
        "                             (Consider changing the string return to an empty DataFrame\n",
        "                             for consistency).\n",
        "    \"\"\"\n",
        "    customer_purchases = superstore_data[superstore_data['Customer ID'] == customer_id]\n",
        "    if customer_purchases.empty:\n",
        "          print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "          return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # Get last product bought\n",
        "    last_purchase = customer_purchases.sort_values('Order Date', ascending=False).iloc[0]\n",
        "    last_product_id = last_purchase['Product ID']\n",
        "    last_product_name = last_purchase['Product Name']\n",
        "\n",
        "    print(f\"Based on last product purchased (ID: {last_product_id}): {last_product_name}\")\n",
        "    return get_content_similar_items(last_product_id, top_n)\n",
        "\n",
        "def recommend_collaborative(customer_id, top_n=5):\n",
        "    \"\"\"Recommends products to a customer based on collaborative filtering.\n",
        "\n",
        "    Aggregates similarity scores from items the customer has purchased to find\n",
        "    new items that are similar based on co-purchase patterns across all users.\n",
        "    Excludes items already purchased by the customer.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the customer.\n",
        "        top_n (int, optional): The number of products to recommend. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the top_n recommended products\n",
        "                             with columns ['Product ID', 'Product Name', 'Category',\n",
        "                             'Sub-Category']. Returns a string message if the customer\n",
        "                             has no history or suitable product data isn't found.\n",
        "                             (Consider changing string returns to an empty DataFrame).\n",
        "    \"\"\"\n",
        "\n",
        "    customer_data, purchased_ids = get_customer_data(customer_id, superstore_data)\n",
        "    if customer_data.empty:\n",
        "        print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # If user has multiple purchases, accumulate similarity\n",
        "    sim_scores = None\n",
        "    for pid in purchased_ids:\n",
        "        if pid not in product_similarity_df.columns:\n",
        "            continue\n",
        "        product_scores = product_similarity_df[pid]\n",
        "        sim_scores = product_scores if sim_scores is None else sim_scores + product_scores\n",
        "\n",
        "    if sim_scores is None:\n",
        "        print(f\"No valid products found for similarity for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # Normalize if multiple products\n",
        "    sim_scores = sim_scores / len(purchased_ids)\n",
        "\n",
        "    # Remove already purchased products\n",
        "    sim_scores = sim_scores.drop(labels=purchased_ids, errors='ignore')\n",
        "\n",
        "    # Top N similar products\n",
        "    top_ids = sim_scores.sort_values(ascending=False).head(top_n).index\n",
        "\n",
        "    return product_popularity[product_popularity['Product ID'].isin(top_ids)][[\n",
        "        'Product ID', 'Product Name', 'Category', 'Sub-Category'\n",
        "    ]]\n",
        "\n",
        "def recommend_hybrid(customer_id, top_n=5, w_content=0.4, w_collab=0.4, w_pop=0.2):\n",
        "    \"\"\"\n",
        "    Recommends products using a hybrid approach combining content similarity,\n",
        "    collaborative similarity, and global popularity.\n",
        "    \"\"\"\n",
        "    customer_data, purchased_ids = get_customer_data(customer_id, superstore_data)\n",
        "    if customer_data.empty:\n",
        "        print(f\"No purchase history found for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --- 1. Calculate Average Content Similarity Scores ---\n",
        "    purchased_idxs_content = [product_indices[pid] for pid in purchased_ids if pid in product_indices]\n",
        "    if not purchased_idxs_content:\n",
        "        print(f\"No purchased products for customer '{customer_id}' found in content product index.\")\n",
        "        # Could potentially proceed without content score or return empty\n",
        "        avg_content_sim_scores = np.zeros(len(products)) # Assign zero score if no history match\n",
        "    else:\n",
        "        # Average similarity to user's purchase history\n",
        "        valid_idxs = [idx for idx in purchased_idxs_content if idx < cosine_sim.shape[0]]\n",
        "        if not valid_idxs:\n",
        "            print(f\"No valid content-based product indices for customer '{customer_id}'.\")\n",
        "            avg_content_sim_scores = np.zeros(len(products))\n",
        "        else:\n",
        "            avg_content_sim_scores = sum(cosine_sim[idx] for idx in valid_idxs) / len(valid_idxs)\n",
        "\n",
        "    content_df = pd.DataFrame({\n",
        "        'Product ID': products['Product ID'], # Use Product ID from the 'products' DataFrame\n",
        "        'content_score': avg_content_sim_scores\n",
        "    })\n",
        "\n",
        "    # --- 2. Calculate Average Collaborative Similarity Scores ---\n",
        "    sim_scores_collab = None\n",
        "    valid_purchased_ids_count = 0\n",
        "    for pid in purchased_ids:\n",
        "        if pid not in product_similarity_df.columns:\n",
        "            continue\n",
        "        product_scores = product_similarity_df[pid]\n",
        "        sim_scores_collab = product_scores if sim_scores_collab is None else sim_scores_collab + product_scores\n",
        "        valid_purchased_ids_count += 1\n",
        "\n",
        "    if sim_scores_collab is None:\n",
        "        print(f\"No valid products found for collaborative similarity for customer '{customer_id}'.\")\n",
        "         # Assign zero score if no history match in collaborative matrix\n",
        "        collab_df = pd.DataFrame({'Product ID': product_similarity_df.columns, 'collab_score': 0.0})\n",
        "    else:\n",
        "        avg_collab_sim_scores = sim_scores_collab / valid_purchased_ids_count\n",
        "        collab_df = avg_collab_sim_scores.reset_index()\n",
        "        collab_df.columns = ['Product ID', 'collab_score']\n",
        "\n",
        "    # --- 3. Combine Scores ---\n",
        "    # Start with all products and their popularity\n",
        "    combined_df = product_popularity[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'popularity_score']].copy()\n",
        "\n",
        "    # Merge content scores\n",
        "    combined_df = pd.merge(combined_df, content_df, on='Product ID', how='left')\n",
        "    combined_df['content_score'] = combined_df['content_score'].fillna(0) # Handle products not in content matrix (if any)\n",
        "\n",
        "    # Merge collaborative scores\n",
        "    combined_df = pd.merge(combined_df, collab_df, on='Product ID', how='left')\n",
        "    combined_df['collab_score'] = combined_df['collab_score'].fillna(0) # Handle products not in collab matrix\n",
        "\n",
        "    # Filter out already purchased items\n",
        "    combined_df = combined_df[~combined_df['Product ID'].isin(purchased_ids)]\n",
        "\n",
        "    # Calculate final hybrid score\n",
        "    combined_df['final_score'] = (\n",
        "        w_content * combined_df['content_score'] +\n",
        "        w_collab * combined_df['collab_score'] +\n",
        "        w_pop * combined_df['popularity_score']\n",
        "    )\n",
        "\n",
        "    # Get top N recommendations\n",
        "    final_recommendations = combined_df.sort_values(by='final_score', ascending=False).head(top_n)\n",
        "\n",
        "    return final_recommendations[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'final_score']]"
      ],
      "metadata": {
        "id": "SsHMrd2VkK9y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 5. Example Usage ==="
      ],
      "metadata": {
        "id": "hTLkJLiOity3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if top_customer_id:\n",
        "     customer_example_id = top_customer_id\n",
        "else:\n",
        "     print(\"WARN: Using default customer ID as top customer wasn't found.\")\n",
        "     customer_example_id = 'CG-12520' # Fallback to original if needed\n",
        "\n",
        "num_recommendations = 5\n",
        "\n",
        "customer_history_context, purchased_ids_context = get_customer_data(customer_example_id, superstore_data)\n",
        "\n",
        "if customer_history_context.empty:\n",
        "    print(f\"\\nWARN: No purchase history found for example customer '{customer_example_id}'. Cannot show context.\")\n",
        "    # Depending on your functions, recommendations might still work (e.g., global popular) or return empty.\n",
        "else:\n",
        "    print(f\"\\nCustomer Purchase Context (from full history):\")\n",
        "    print(f\"  Total Unique Products Purchased: {len(purchased_ids_context)}\")\n",
        "\n",
        "    # --- Last Purchase ---\n",
        "    # Sort by date to find the most recent purchase in the full history\n",
        "    customer_history_context_sorted = customer_history_context.sort_values('Order Date', ascending=False)\n",
        "    last_purchase = customer_history_context_sorted.iloc[0]\n",
        "    print(f\"  Last Purchase (on {last_purchase['Order Date'].date()}):\")\n",
        "    print(f\"    - Product: '{last_purchase['Product Name']}' (ID: {last_purchase['Product ID']})\")\n",
        "    # Note: recommend_content_based uses this logic internally. Printing it here gives context.\n",
        "\n",
        "    # --- Most Frequent Purchases (e.g., Top 3) ---\n",
        "    print(f\"  Most Frequent Purchases:\")\n",
        "    # Count occurrences of each product ID in the history\n",
        "    freq_counts = customer_history_context['Product ID'].value_counts()\n",
        "    # Get names for the top IDs\n",
        "    top_freq_ids = freq_counts.head(3).index.tolist()\n",
        "    # Look up names (using product_popularity which has unique IDs and names)\n",
        "    top_freq_products = product_popularity[product_popularity['Product ID'].isin(top_freq_ids)][['Product ID', 'Product Name']]\n",
        "    # Merge to show count (optional, simpler to just list names)\n",
        "    for pid in top_freq_ids:\n",
        "         name = top_freq_products[top_freq_products['Product ID'] == pid]['Product Name'].iloc[0]\n",
        "         count = freq_counts[pid]\n",
        "         print(f\"    - '{name}' ({count} times)\")\n",
        "\n",
        "\n",
        "    # --- Top Categories/Sub-Categories ---\n",
        "    # Use the helper function to get preferences from the full history\n",
        "    top_cats, top_subcats = get_customer_preferences(customer_example_id, superstore_data)\n",
        "    print(f\"  Top Categories (by purchase frequency): {top_cats[:3]}\") # Show top 3\n",
        "    print(f\"  Top Sub-Categories (by purchase frequency): {top_subcats[:3]}\") # Show top 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1hBdbzGuJRU",
        "outputId": "b2d42375-ca66-4ea7-8b80-f92f0a852a7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Customer Purchase Context (from full history):\n",
            "  Total Unique Products Purchased: 36\n",
            "  Last Purchase (on 2017-12-10):\n",
            "    - Product: 'Contract Clock, 14\", Brown' (ID: FUR-FU-10001475)\n",
            "  Most Frequent Purchases:\n",
            "    - 'Fellowes 8 Outlet Superior Workstation Surge Protector' (2 times)\n",
            "    - 'Fellowes PB200 Plastic Comb Binding Machine' (1 times)\n",
            "    - 'Motorla HX550 Universal Bluetooth Headset' (1 times)\n",
            "  Top Categories (by purchase frequency): ['Office Supplies', 'Technology', 'Furniture']\n",
            "  Top Sub-Categories (by purchase frequency): ['Binders', 'Phones', 'Furnishings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Display Recommendations ---\n",
        "print(\"\\n--- Generating Recommendations ---\")\n",
        "\n",
        "print(f\"\\nTop {num_recommendations} Popular Products (Unseen by Customer):\")\n",
        "print(recommend_popular(customer_id=customer_example_id, personalized=False, n=num_recommendations))\n",
        "\n",
        "print(f\"\\nTop {num_recommendations} Content-Based Recommendations (Based on Last Purchase):\")\n",
        "print(recommend_content_based(customer_example_id, top_n=num_recommendations))\n",
        "\n",
        "print(f\"\\nTop {num_recommendations} Collaborative Recommendations (Based on Customer History):\")\n",
        "print(recommend_collaborative(customer_example_id, top_n=num_recommendations))\n",
        "\n",
        "print(f\"\\nTop {num_recommendations} Advanced Hybrid Recommendations (Content+Collab+Pop):\")\n",
        "print(recommend_hybrid(customer_example_id, top_n=num_recommendations))"
      ],
      "metadata": {
        "id": "45HD3ts26V_e",
        "outputId": "ac383161-fda3-4128-e0d8-7679747dad6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating Recommendations ---\n",
            "\n",
            "Top 5 Popular Products (Unseen by Customer):\n",
            "           Product ID                                       Product Name  \\\n",
            "1569  TEC-AC-10003832                 Logitech P710e Mobile Speakerphone   \n",
            "1144  OFF-PA-10001970                                         Xerox 1881   \n",
            "694   OFF-BI-10001524  GBC Premium Transparent Covers with Diagonal L...   \n",
            "721   OFF-BI-10002026                            Avery Arch Ring Binders   \n",
            "93    FUR-CH-10002647         Situations Contoured Folding Chairs, 4/Set   \n",
            "\n",
            "             Category Sub-Category  Quantity  \n",
            "1569       Technology  Accessories        75  \n",
            "1144  Office Supplies        Paper        70  \n",
            "694   Office Supplies      Binders        67  \n",
            "721   Office Supplies      Binders        64  \n",
            "93          Furniture       Chairs        64  \n",
            "\n",
            "Top 5 Content-Based Recommendations (Based on Last Purchase):\n",
            "Based on last product purchased (ID: FUR-FU-10001475): Contract Clock, 14\", Brown\n",
            "                  Product Name         Category Sub-Category\n",
            "4550                   Avery 5  Office Supplies       Labels\n",
            "963   Avery File Folder Labels  Office Supplies       Labels\n",
            "1609       Avery Binder Labels  Office Supplies      Binders\n",
            "2475                  Avery 50  Office Supplies       Labels\n",
            "1281                  Avery 48  Office Supplies       Labels\n",
            "\n",
            "Top 5 Collaborative Recommendations (Based on Customer History):\n",
            "           Product ID                                       Product Name  \\\n",
            "197   FUR-FU-10001861  Floodlight Indoor Halogen Bulbs, 1 Bulb per Pa...   \n",
            "215   FUR-FU-10002191                       G.E. Halogen Desk Lamp Bulbs   \n",
            "495   OFF-AR-10000817             Manco Dry-Lighter Erasable Highlighter   \n",
            "702   OFF-BI-10001634                    Wilson Jones Active Use Binders   \n",
            "1635  TEC-MA-10001695  Zebra GK420t Direct Thermal/Thermal Transfer P...   \n",
            "\n",
            "             Category Sub-Category  \n",
            "197         Furniture  Furnishings  \n",
            "215         Furniture  Furnishings  \n",
            "495   Office Supplies          Art  \n",
            "702   Office Supplies      Binders  \n",
            "1635       Technology     Machines  \n",
            "\n",
            "Top 5 Advanced Hybrid Recommendations (Content+Collab+Pop):\n",
            "           Product ID                                       Product Name  \\\n",
            "1569  TEC-AC-10003832                 Logitech P710e Mobile Speakerphone   \n",
            "1144  OFF-PA-10001970                                         Xerox 1881   \n",
            "721   OFF-BI-10002026                            Avery Arch Ring Binders   \n",
            "694   OFF-BI-10001524  GBC Premium Transparent Covers with Diagonal L...   \n",
            "93    FUR-CH-10002647         Situations Contoured Folding Chairs, 4/Set   \n",
            "\n",
            "             Category Sub-Category  final_score  \n",
            "1569       Technology  Accessories     0.205096  \n",
            "1144  Office Supplies        Paper     0.204604  \n",
            "721   Office Supplies      Binders     0.194175  \n",
            "694   Office Supplies      Binders     0.191955  \n",
            "93          Furniture       Chairs     0.176610  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 6. Evaluation ==="
      ],
      "metadata": {
        "id": "RxDkBumng3q2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWmSoeATiZYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}