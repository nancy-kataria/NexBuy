{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nancy-kataria/NexTrade/blob/main/product_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== Imports ==="
      ],
      "metadata": {
        "id": "TxLsn_3YgSds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "FQjFG7BkiGKB"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "metadata": {
        "id": "cBKpCzmXbrpJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 1. Dataset Download ==="
      ],
      "metadata": {
        "id": "BitMW-zx-j2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "print(\"Dowlaod Dataset...\")\n",
        "path = kagglehub.dataset_download(\"vivek468/superstore-dataset-final\")\n",
        "print(f\"Dataset downloaded to: {path}\")\n",
        "csv_file_path = os.path.join(path, \"Sample - Superstore.csv\")\n",
        "print(f\"Reading data from: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "xj6z5B1j-nv7",
        "outputId": "5cbd5554-b5c0-46fe-eeb6-2155b2cb67c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dowlaod Dataset...\n",
            "Dataset downloaded to: /kaggle/input/superstore-dataset-final\n",
            "Reading data from: /kaggle/input/superstore-dataset-final/Sample - Superstore.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 2. Load & Clean Data ==="
      ],
      "metadata": {
        "id": "0fos8cod7pJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    superstore_data = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {csv_file_path}.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "Mh4kbf0HjNH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93132977-cdcd-45c0-d261-058851004ab7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep necessary columns\n",
        "columns_to_keep = ['Order ID', 'Order Date', 'Ship Date', 'Customer ID', 'Product ID', 'Product Name', 'Sales', 'Quantity', 'Category', 'Sub-Category']\n",
        "superstore_data = superstore_data[columns_to_keep]"
      ],
      "metadata": {
        "id": "_fTuhoxWlcUH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows to check the data\n",
        "print(\"First 5 rows of data:\")\n",
        "print(superstore_data.head())"
      ],
      "metadata": {
        "id": "4bSD5nfglcFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e12cd82-9cfb-4abe-eee2-58a9ef6e5891"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of data:\n",
            "         Order ID  Order Date   Ship Date Customer ID       Product ID                                       Product Name     Sales  Quantity         Category Sub-Category\n",
            "0  CA-2016-152156   11/8/2016  11/11/2016    CG-12520  FUR-BO-10001798                  Bush Somerset Collection Bookcase  261.9600         2        Furniture    Bookcases\n",
            "1  CA-2016-152156   11/8/2016  11/11/2016    CG-12520  FUR-CH-10000454  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3        Furniture       Chairs\n",
            "2  CA-2016-138688   6/12/2016   6/16/2016    DV-13045  OFF-LA-10000240  Self-Adhesive Address Labels for Typewriters b...   14.6200         2  Office Supplies       Labels\n",
            "3  US-2015-108966  10/11/2015  10/18/2015    SO-20335  FUR-TA-10000577      Bretford CR4500 Series Slim Rectangular Table  957.5775         5        Furniture       Tables\n",
            "4  US-2015-108966  10/11/2015  10/18/2015    SO-20335  OFF-ST-10000760                     Eldon Fold 'N Roll Cart System   22.3680         2  Office Supplies      Storage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dates\n",
        "superstore_data['Order Date'] = pd.to_datetime(superstore_data['Order Date'])\n",
        "superstore_data['Ship Date'] = pd.to_datetime(superstore_data['Ship Date'])"
      ],
      "metadata": {
        "id": "v8JDsd7ZkKAk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if dropna() is overkill\n",
        "print(superstore_data[columns_to_keep].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C96ihRBJcYV_",
        "outputId": "5f69db43-d5e1-4416-c434-536f00bc409b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Order ID        0\n",
            "Order Date      0\n",
            "Ship Date       0\n",
            "Customer ID     0\n",
            "Product ID      0\n",
            "Product Name    0\n",
            "Sales           0\n",
            "Quantity        0\n",
            "Category        0\n",
            "Sub-Category    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop rows with missing any necessary columns\n",
        "superstore_data.dropna(subset=columns_to_keep, inplace=True)"
      ],
      "metadata": {
        "id": "omwT_AcdkKXc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Finding Customers with Most Transactions ---\")\n",
        "\n",
        "# Count the number of rows (transaction line items) for each Customer ID\n",
        "customer_transaction_counts = superstore_data.groupby('Customer ID').size()\n",
        "\n",
        "# Sort the counts in descending order\n",
        "customer_transaction_counts_sorted = customer_transaction_counts.sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 5 Customers by Number of Transaction Entries:\")\n",
        "print(customer_transaction_counts_sorted.head(5))\n",
        "\n",
        "# Get the Customer ID with the absolute highest count\n",
        "if not customer_transaction_counts_sorted.empty:\n",
        "    top_customer_id = customer_transaction_counts_sorted.index[0]\n",
        "    top_customer_count = customer_transaction_counts_sorted.iloc[0]\n",
        "    print(f\"\\nCustomer with the most transaction entries: '{top_customer_id}' ({top_customer_count} entries)\")\n",
        "else:\n",
        "    top_customer_id = None # Handle case where data might be empty\n",
        "    print(\"\\nCould not determine top customer.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCw9orMdu8YU",
        "outputId": "4cb2cfe2-486d-4839-a490-2f453eb297b0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Finding Customers with Most Transactions ---\n",
            "Top 5 Customers by Number of Transaction Entries:\n",
            "Customer ID\n",
            "WB-21850    37\n",
            "MA-17560    34\n",
            "JL-15835    34\n",
            "PP-18955    34\n",
            "EH-13765    32\n",
            "dtype: int64\n",
            "\n",
            "Customer with the most transaction entries: 'WB-21850' (37 entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== (TEST STAGE) 2b. Evaluation Split (Time-Based) ==="
      ],
      "metadata": {
        "id": "n-pBRT2gpfWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Splitting Data for Evaluation ---\")\n",
        "# Sort data by order date\n",
        "superstore_data_sorted = superstore_data.sort_values('Order Date').copy()\n",
        "superstore_data_sorted.reset_index(drop=True, inplace=True) # Optional: Reset index\n",
        "\n",
        "# Define split point (e.g., 80% train, 20% test based on row count after sorting)\n",
        "# Alternatively, pick a specific date for splitting\n",
        "split_index = int(len(superstore_data_sorted) * 0.8)\n",
        "train_df = superstore_data_sorted.iloc[:split_index].copy()\n",
        "test_df = superstore_data_sorted.iloc[split_index:].copy()\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Testing data shape: {test_df.shape}\")\n",
        "if not train_df.empty:\n",
        "    print(f\"Training data period: {train_df['Order Date'].min()} to {train_df['Order Date'].max()}\")\n",
        "if not test_df.empty:\n",
        "    print(f\"Testing data period: {test_df['Order Date'].min()} to {test_df['Order Date'].max()}\")\n",
        "\n",
        "# Identify users present in the test set for evaluation\n",
        "test_users = test_df['Customer ID'].unique()\n",
        "print(f\"Number of unique users in test set: {len(test_users)}\")"
      ],
      "metadata": {
        "id": "0wNF5fG4pj3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 3. Precomputation  ==="
      ],
      "metadata": {
        "id": "go59KyXFg9VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Product Popularity\n",
        "product_popularity = superstore_data.groupby('Product ID').agg({\n",
        "    'Product Name': 'first',\n",
        "    'Category': 'first',\n",
        "    'Sub-Category': 'first',\n",
        "    'Quantity': 'sum',\n",
        "    'Sales': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Normalize popularity score\n",
        "product_popularity['popularity_score'] = product_popularity['Quantity'] / product_popularity['Quantity'].max()\n",
        "\n",
        "# 2. Content-Based Info Preparation\n",
        "superstore_data['product_info'] = (\n",
        "    superstore_data['Product Name'].astype(str) + ' ' +\n",
        "    superstore_data['Category'].astype(str) + ' ' +\n",
        "    superstore_data['Sub-Category'].astype(str)\n",
        ")\n",
        "\n",
        "# One row per product\n",
        "products = superstore_data.drop_duplicates(subset='Product ID')[\n",
        "    ['Product ID', 'Product Name', 'Category', 'Sub-Category', 'product_info']\n",
        "]\n",
        "\n",
        "# 3. TF-IDF Matrix and Cosine Similarity\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(products['product_info'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 4. Product Index Mapping\n",
        "product_indices = pd.Series(products.index, index=products['Product ID']).drop_duplicates()\n",
        "\n",
        "# 5. User-Product Matrix and Product Similarity for Collaborative Filtering\n",
        "# Create user-product interaction matrix\n",
        "user_product_matrix = superstore_data.pivot_table(\n",
        "    index='Customer ID',\n",
        "    columns='Product ID',\n",
        "    values='Quantity',\n",
        "    aggfunc='sum'\n",
        ").fillna(0)\n",
        "\n",
        "\n",
        "# Compute item-item similarity - similar to item you liked\n",
        "product_similarity = cosine_similarity(user_product_matrix.T)\n",
        "\n",
        "# Store as DataFrame\n",
        "product_similarity_df = pd.DataFrame(\n",
        "    product_similarity,\n",
        "    index=user_product_matrix.columns,\n",
        "    columns=user_product_matrix.columns\n",
        ")"
      ],
      "metadata": {
        "id": "c9fGWIFgg_Mp"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 4. Recommendation Functions ==="
      ],
      "metadata": {
        "id": "M0vdvNDY7zWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Helper Functions ===\n",
        "def get_customer_orders_and_products(customer_id, df):\n",
        "    \"\"\"Fetches purchase data and unique purchased product IDs for a customer.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the target customer.\n",
        "        df (pd.DataFrame): The main DataFrame containing all transaction data.\n",
        "                           Must include 'Customer ID' and 'Product ID'.\n",
        "\n",
        "    Returns:\n",
        "        tuple[pd.DataFrame, np.ndarray]: A tuple containing:\n",
        "            - order_history (pd.DataFrame): A DataFrame filtered to only include\n",
        "                                            rows for the given customer_id. Returns\n",
        "                                            an empty DataFrame if customer not found.\n",
        "            - product_ids (np.ndarray): A NumPy array of unique Product IDs\n",
        "                                          purchased by the customer. Returns an\n",
        "                                          empty array if customer not found.\n",
        "    \"\"\"\n",
        "    order_history = df[df['Customer ID'] == customer_id].copy()\n",
        "    # Using .copy() is good practice here to prevent potential SettingWithCopyWarning\n",
        "    # if the returned DataFrame is modified later in another function.\n",
        "    product_ids = order_history['Product ID'].unique()\n",
        "    return order_history, product_ids\n",
        "\n",
        "def get_unseen_products(customer_id, df, product_df):\n",
        "    \"\"\"\n",
        "    Get a list of products the customer hasn't purchased yet\n",
        "\n",
        "    Args:\n",
        "      customer_id (str): ID of the target customer.\n",
        "      df (pd.DataFrame): Full transaction data (e.g., superstore_data)\n",
        "                           used to find customer history.\n",
        "      product_df (pd.DataFrame): DataFrame of all products to recommend\n",
        "                                   from (e.g., product_popularity).\n",
        "\n",
        "    Returns:\n",
        "      pd.DataFrame: filtered product_df with only unseen products\n",
        "      pd.DataFrame: list of purchased Product IDs for fallback logic\n",
        "    \"\"\"\n",
        "\n",
        "    _, product_ids = get_customer_orders_and_products(customer_id, df)\n",
        "    return product_df[~product_df['Product ID'].isin(product_ids)], product_ids\n",
        "\n",
        "def add_fallback_if_needed(recommendations, product_ids, product_df, n, by):\n",
        "    \"\"\"\n",
        "    Add fallback recommendations if there aren't enough unseen products to recommend\n",
        "    This uses globally popular products (based on 'Quantity' or 'Sales') to fill the gap\n",
        "\n",
        "    Args:\n",
        "      recommendations: filtered list of unseen, ranked products\n",
        "      purchased_ids: list of already purchased product IDs\n",
        "      product_df: global product list (e.g., product_popularity)\n",
        "      n: number of products we want to recommend\n",
        "      by: popularity metric ('Quantity' or 'Sales')\n",
        "\n",
        "    Returns:\n",
        "     pd.DataFrame: final DataFrame of n recommendations\n",
        "    \"\"\"\n",
        "\n",
        "    if len(recommendations) < n:\n",
        "        print(f\"Customer has only {len(recommendations)} new products available. Showing global popular items instead.\")\n",
        "        fallback = get_global_popular_products(top_n=n, by=by)\n",
        "        fallback = fallback[~fallback['Product ID'].isin(product_ids)]\n",
        "        recommendations = pd.concat([recommendations, fallback]).drop_duplicates('Product ID')\n",
        "    return recommendations\n",
        "\n",
        "def get_customer_preferences(customer_id, df):\n",
        "    \"\"\"\n",
        "    Gets the customer's most frequent categories and sub-categories.\n",
        "\n",
        "    Analyzes a customer's purchase history to find the categories and\n",
        "    sub-categories they interact with most often, based on the count\n",
        "    of purchases in each. Used for personalized popularity recommendations.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the target customer.\n",
        "        df (pd.DataFrame): The DataFrame containing transaction data, including\n",
        "                           'Customer ID', 'Category', and 'Sub-Category' columns.\n",
        "\n",
        "    Returns:\n",
        "        tuple[list[str], list[str]]: A tuple containing two lists:\n",
        "            - The first list contains category names, sorted by frequency (most frequent first).\n",
        "            - The second list contains sub-category names, sorted by frequency.\n",
        "            Returns two empty lists ([], []) if the customer has no purchase history in df.\n",
        "    \"\"\"\n",
        "    order_history, _ = get_customer_orders_and_products(customer_id, df)\n",
        "    if order_history.empty:\n",
        "        return [], []\n",
        "    top_categories = order_history['Category'].value_counts().index.tolist()\n",
        "    top_subcategories = order_history['Sub-Category'].value_counts().index.tolist()\n",
        "    return top_categories, top_subcategories"
      ],
      "metadata": {
        "id": "SsHMrd2VkK9y"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Calculation  Functions ===\n",
        "def get_global_popular_products(top_n=5, by='Quantity'):\n",
        "    \"\"\"\n",
        "    Recommends top-N globally popular products. Sorts all products based on a specified metric ('Quantity' or 'Sales') and returns the top N. Does not consider customer history.\n",
        "\n",
        "    Args:\n",
        "        top_n (int, optional): The number of products to recommend. Defaults to 10.\n",
        "        by (str, optional): The metric to sort popularity by ('Quantity' or 'Sales'). Defaults to 'Quantity'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the top N popular products with columns ['Product ID', 'Product Name', 'Category', 'Sub-Category', <by>]. Returns an empty DataFrame if an invalid 'by' parameter is provided (though it currently raises ValueError).\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If 'by' is not 'Quantity' or 'Sales'.\n",
        "    \"\"\"\n",
        "    if by not in ['Quantity', 'Sales']:\n",
        "        raise ValueError(\"Parameter 'by' must be either 'Quantity' or 'Sales'\")\n",
        "\n",
        "    return product_popularity.sort_values(by=by, ascending=False).head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', by]]\n",
        "\n",
        "def get_content_similar_items(product_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends products similar to a given product based on content.\n",
        "\n",
        "      Uses precomputed TF-IDF vectors and cosine similarity based on product\n",
        "      name, category, and sub-category.\n",
        "\n",
        "      Args:\n",
        "          product_id (str): The ID of the product to find similar items for.\n",
        "          top_n (int, optional): The number of similar products to return.\n",
        "                                Defaults to 5.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A DataFrame containing the top_n similar products with\n",
        "                        columns ['Product Name', 'Category', 'Sub-Category'].\n",
        "                        Returns an empty DataFrame if the product_id is not found.\n",
        "      \"\"\"\n",
        "    if product_id not in product_indices.index:\n",
        "      print(f\"Product ID '{product_id}' not found in product indices.\")\n",
        "      return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    idx = product_indices[product_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "    product_idxs = [i[0] for i in sim_scores]\n",
        "\n",
        "    return products.iloc[product_idxs][['Product ID', 'Product Name', 'Category', 'Sub-Category']]\n",
        "\n",
        "def get_collaborative_similar_items(product_id, top_n=5):\n",
        "    \"\"\"Recommends products similar to a given product using item-item collaborative filtering.\n",
        "\n",
        "    Uses a precomputed product similarity matrix based on user co-purchase patterns.\n",
        "\n",
        "    Args:\n",
        "        product_id (str): The ID of the product to find collaboratively similar items for.\n",
        "        top_n (int, optional): The number of similar products to return. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the top_n similar products\n",
        "                             with columns ['Product ID', 'Similarity Score', 'Product Name',\n",
        "                             'Category', 'Sub-Category']. Returns a string message if the\n",
        "                             product_id is not found in the similarity matrix. (Consider\n",
        "                             changing string returns to an empty DataFrame).\n",
        "    \"\"\"\n",
        "\n",
        "    if product_id not in product_similarity_df.columns:\n",
        "        print(f\"Product {product_id} not found in dataset.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "    similar_scores = product_similarity_df[product_id].sort_values(ascending=False)\n",
        "    # return similar_scores[1:top_n+1]\n",
        "\n",
        "    recommended = similar_scores[1:top_n+1].reset_index()\n",
        "    recommended.columns = ['Product ID', 'Similarity Score']\n",
        "    return recommended.merge(\n",
        "        product_popularity[['Product ID', 'Product Name', 'Category', 'Sub-Category']],\n",
        "        on='Product ID', how='left'\n",
        "    )"
      ],
      "metadata": {
        "id": "upq_-CyItnj0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Main Recommendation Functions ===\n",
        "def recommend_popular(customer_id=None, top_n=5, by='Quantity'):\n",
        "    \"\"\"\n",
        "    Recommends popular products, optionally personalized for a customer.\n",
        "\n",
        "    Modes:\n",
        "    1. Global: If customer_id is None, returns globally popular products.\n",
        "    2. Unseen for Customer: Returns globally popular products not yet purchased by the customer,\n",
        "       with fallback if fewer than n are found.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str, optional): The ID of the customer. Defaults to None.\n",
        "        top_n (int, optional): The number of products to recommend. Defaults to 10.\n",
        "        by (str, optional): The metric for popularity ('Quantity' or 'Sales').\n",
        "                            Defaults to 'Quantity'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Top-N recommended products.\n",
        "\n",
        "    \"\"\"\n",
        "    if by not in ['Quantity', 'Sales']:\n",
        "        raise ValueError(\"Parameter 'by' must be either 'Quantity' or 'Sales'\")\n",
        "\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(top_n=top_n)\n",
        "\n",
        "    # Case 2: Exclude products already purchased\n",
        "    unseen_products, product_ids = get_unseen_products(customer_id, superstore_data, product_popularity)\n",
        "    unseen_products = unseen_products.sort_values(by=by, ascending=False)\n",
        "\n",
        "    # Apply fallback if needed\n",
        "    final = add_fallback_if_needed(unseen_products, product_ids, product_popularity, top_n, by)\n",
        "\n",
        "    return final.head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', by]]\n",
        "\n",
        "def recommend_content_based(customer_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends products similar to the last item purchased by a customer.\n",
        "\n",
        "    Finds the customer's most recent purchase and then uses content-based\n",
        "    similarity (get_content_similar_items) to find similar items.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the customer.\n",
        "        top_n (int, optional): The number of similar products to recommend.\n",
        "                               Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the recommended products\n",
        "                             (from get_content_similar_items) or a string message\n",
        "                             if the customer has no purchase history.\n",
        "                             (Consider changing the string return to an empty DataFrame\n",
        "                             for consistency).\n",
        "    \"\"\"\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(top_n=top_n)\n",
        "\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "          print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "          return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # Get last product bought\n",
        "    last_purchase = order_history.sort_values('Order Date', ascending=False).iloc[0]\n",
        "    last_product_id = last_purchase['Product ID']\n",
        "    last_product_name = last_purchase['Product Name']\n",
        "    print(f\"Based on last product purchased (ID: {last_product_id}): {last_product_name}\")\n",
        "\n",
        "    # Get content-based similar items\n",
        "    similar_items = get_content_similar_items(last_product_id, top_n * 2)  # get more to allow filtering\n",
        "\n",
        "    # Exclude already purchased\n",
        "    similar_items = similar_items[~similar_items['Product ID'].isin(product_ids)]\n",
        "\n",
        "    return similar_items.head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category']]\n",
        "\n",
        "def recommend_collaborative(customer_id, top_n=5):\n",
        "    \"\"\"Recommends products to a customer based on collaborative filtering.\n",
        "\n",
        "    Aggregates similarity scores from items the customer has purchased to find\n",
        "    new items that are similar based on co-purchase patterns across all users.\n",
        "    Excludes items already purchased by the customer.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the customer.\n",
        "        top_n (int, optional): The number of products to recommend. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the top_n recommended products\n",
        "                             with columns ['Product ID', 'Product Name', 'Category',\n",
        "                             'Sub-Category']. Returns a string message if the customer\n",
        "                             has no history or suitable product data isn't found.\n",
        "                             (Consider changing string returns to an empty DataFrame).\n",
        "    \"\"\"\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(top_n=top_n)\n",
        "\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "        print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # If user has multiple purchases, accumulate similarity\n",
        "    total_collab_scores = None\n",
        "    valid_count = 0\n",
        "    for pid in product_ids:\n",
        "        if pid not in product_similarity_df.columns:\n",
        "            continue\n",
        "        product_scores = product_similarity_df[pid]\n",
        "        total_collab_scores = product_scores if total_collab_scores is None else total_collab_scores + product_scores\n",
        "        valid_count += 1\n",
        "\n",
        "    if total_collab_scores is None or valid_count == 0:\n",
        "        print(f\"No valid products found for similarity for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Normalize if multiple products\n",
        "    total_collab_scores = total_collab_scores / valid_count\n",
        "\n",
        "    # Remove already purchased products\n",
        "    total_collab_scores = total_collab_scores.drop(labels=product_ids, errors='ignore')\n",
        "\n",
        "    # Get top similar product IDs\n",
        "    top_scores = total_collab_scores.sort_values(ascending=False)\n",
        "    top_ids = top_scores.head(top_n).index.tolist()\n",
        "\n",
        "    # Fetch recommended products\n",
        "    recommendations = product_popularity[product_popularity['Product ID'].isin(top_ids)].copy()\n",
        "    recommendations['Similarity Score'] = top_scores[top_ids].values\n",
        "\n",
        "    # Fallback if not enough items\n",
        "    if len(recommendations) < top_n:\n",
        "        print(f\"Only {len(recommendations)} collaborative recommendations found. Adding fallback items.\")\n",
        "        fallback = get_global_popular_products(top_n=top_n * 2)  # more to ensure enough\n",
        "        fallback = fallback[~fallback['Product ID'].isin(product_ids + top_ids)]\n",
        "        fallback = fallback.head(top_n - len(recommendations))\n",
        "        fallback['Similarity Score'] = 0  # or None, since fallback isn't similarity-based\n",
        "        recommendations = pd.concat([recommendations, fallback])\n",
        "\n",
        "    return recommendations.head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'Similarity Score']]\n",
        "\n",
        "def recommend_hybrid(customer_id, top_n=5, w_content=0.4, w_collab=0.4, w_pop=0.2, show_debug=False):\n",
        "    \"\"\"\n",
        "    Recommends products using a hybrid approach combining content similarity,\n",
        "    collaborative similarity, and global popularity.\n",
        "    \"\"\"\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(top_n=top_n)\n",
        "\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "        print(f\"No purchase history found for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --- 1. Calculate Average Content Similarity Scores ---\n",
        "    purchased_idxs_content = [product_indices[pid] for pid in product_ids if pid in product_indices]\n",
        "    if not purchased_idxs_content:\n",
        "        print(f\"No purchased products for customer '{customer_id}' found in content product index.\")\n",
        "        # Could potentially proceed without content score or return empty\n",
        "        avg_content_sim_scores = np.zeros(len(products)) # Assign zero score if no history match\n",
        "    else:\n",
        "        # Average similarity to user's purchase history\n",
        "        valid_idxs = [idx for idx in purchased_idxs_content if idx < cosine_sim.shape[0]]\n",
        "        if not valid_idxs:\n",
        "            print(f\"No valid content-based product indices for customer '{customer_id}'.\")\n",
        "            avg_content_sim_scores = np.zeros(len(products))\n",
        "        else:\n",
        "            avg_content_sim_scores = sum(cosine_sim[idx] for idx in valid_idxs) / len(valid_idxs)\n",
        "\n",
        "    content_df = pd.DataFrame({\n",
        "        'Product ID': products['Product ID'], # Use Product ID from the 'products' DataFrame\n",
        "        'content_score': avg_content_sim_scores\n",
        "    })\n",
        "\n",
        "    # --- 2. Calculate Average Collaborative Similarity Scores ---\n",
        "    total_collab_sim = None\n",
        "    valid_purchased_ids_count = 0\n",
        "    for pid in product_ids:\n",
        "        if pid not in product_similarity_df.columns:\n",
        "            continue\n",
        "        product_scores = product_similarity_df[pid]\n",
        "        total_collab_sim = product_scores if total_collab_sim is None else total_collab_sim + product_scores\n",
        "        valid_purchased_ids_count += 1\n",
        "\n",
        "    if total_collab_sim is None:\n",
        "        print(f\"No valid products found for collaborative similarity for customer '{customer_id}'.\")\n",
        "         # Assign zero score if no history match in collaborative matrix\n",
        "        collab_df = pd.DataFrame({'Product ID': product_similarity_df.columns, 'collab_score': 0.0})\n",
        "    else:\n",
        "        avg_collab_sim_scores = total_collab_sim / valid_purchased_ids_count\n",
        "        collab_df = avg_collab_sim_scores.reset_index()\n",
        "        collab_df.columns = ['Product ID', 'collab_score']\n",
        "\n",
        "    # --- 3. Combine All Scores ---\n",
        "    # Start with all products and their popularity\n",
        "    combined_df = product_popularity[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'popularity_score']].copy()\n",
        "\n",
        "    # Merge content scores\n",
        "    combined_df = combined_df.merge(content_df, on='Product ID', how='left')\n",
        "    combined_df['content_score'] = combined_df['content_score'].fillna(0)\n",
        "\n",
        "    # Merge collaborative scores\n",
        "    combined_df = combined_df.merge(collab_df, on='Product ID', how='left')\n",
        "    combined_df['collab_score'] = combined_df['collab_score'].fillna(0)\n",
        "\n",
        "    # Filter out already purchased items\n",
        "    combined_df = combined_df[~combined_df['Product ID'].isin(product_ids)].copy()\n",
        "\n",
        "    # --- 4. Normalize All Scores ---\n",
        "    # if not normalize, popularity score is just too high\n",
        "    scaler = MinMaxScaler()\n",
        "    combined_df[['content_score', 'collab_score', 'popularity_score']] = scaler.fit_transform(\n",
        "        combined_df[['content_score', 'collab_score', 'popularity_score']]\n",
        "    )\n",
        "\n",
        "    # --- 5. Calculate Final Score ---\n",
        "    combined_df['final_score'] = (\n",
        "        w_content * combined_df['content_score'] +\n",
        "        w_collab * combined_df['collab_score'] +\n",
        "        w_pop * combined_df['popularity_score']\n",
        "    )\n",
        "\n",
        "    # --- 6. Show Debug Info (Optional) ---\n",
        "    if show_debug:\n",
        "        print(\"\\n[DEBUG] Top products by each score (before final sort):\")\n",
        "        print(combined_df[['Product Name', 'content_score', 'collab_score', 'popularity_score', 'final_score']]\n",
        "              .sort_values(by='final_score', ascending=False).head(10))\n",
        "\n",
        "    # --- 7. Sort and Return ---\n",
        "    final_recommendations = combined_df.sort_values(by='final_score', ascending=False).head(top_n)\n",
        "\n",
        "    # --- 8. Fallback Logic ---\n",
        "    if len(final_recommendations) < top_n:\n",
        "      print(f\"Only {len(final_recommendations)} hybrid recommendations found. Adding fallback items.\")\n",
        "      fallback = get_global_popular_products(n=top_n * 2)\n",
        "      fallback = fallback[~fallback['Product ID'].isin(product_ids + final_recommendations['Product ID'].tolist())]\n",
        "      fallback['final_score'] = 0  # Neutral fallback score\n",
        "      final_recommendations = pd.concat([final_recommendations, fallback.head(top_n - len(final_recommendations))])\n",
        "\n",
        "    return final_recommendations[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'final_score']]"
      ],
      "metadata": {
        "id": "QNVYBKdItr0g"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 5. Example Usage ==="
      ],
      "metadata": {
        "id": "hTLkJLiOity3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_recommendation_output(customer_id, num_recommendations=5):\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Example: Personalized Recommendations for One Customer\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Show context\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "\n",
        "    if order_history.empty:\n",
        "        print(f\"\\nNo purchase history found for customer '{customer_id}'. Showing global popular items instead.\")\n",
        "        print(recommend_popular(customer_id=None, top_n=num_recommendations))\n",
        "        return\n",
        "\n",
        "    print(f\"\\n Purchase History Summary for Customer: {customer_id}\")\n",
        "    print(f\"  - Total Unique Products Purchased: {len(product_ids)}\")\n",
        "\n",
        "    # Last purchase\n",
        "    last_purchase = order_history.sort_values('Order Date', ascending=False).iloc[0]\n",
        "    print(f\"  - Most Recent Purchase: '{last_purchase['Product Name']}' on {last_purchase['Order Date'].date()} — {last_purchase['Category']} / {last_purchase['Sub-Category']}\")\n",
        "\n",
        "    # Frequent items\n",
        "    freq_counts = order_history['Product ID'].value_counts()\n",
        "    top_freq_ids = freq_counts.head(3).index.tolist()\n",
        "    print(\"  - Most Frequently Purchased Items:\")\n",
        "    for pid in top_freq_ids:\n",
        "        row = superstore_data[superstore_data['Product ID'] == pid].iloc[0]\n",
        "        print(f\"    → '{row['Product Name']}' ({freq_counts[pid]} times) — {row['Category']} / {row['Sub-Category']}\")\n",
        "\n",
        "    # Category preferences\n",
        "    top_cats, top_subcats = get_customer_preferences(customer_id, superstore_data)\n",
        "    print(f\"  - Top Categories: {', '.join(top_cats[:3])}\")\n",
        "    print(f\"  - Top Sub-Categories: {', '.join(top_subcats[:3])}\")\n",
        "\n",
        "    print(\"\\n Customer Purchase History\")\n",
        "    history_sorted = order_history.sort_values('Order Date', ascending=False).copy()\n",
        "    for _, row in history_sorted.iterrows():\n",
        "        print(f\"  [{row['Order Date'].date()}] {row['Product Name']} (ID: {row['Product ID']}) — {row['Category']} / {row['Sub-Category']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\" Recommendation Outputs\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    def explain_recommendations(name, df, context_col=None):\n",
        "        print(f\"\\nTop {num_recommendations} {name} Recommendations:\")\n",
        "        if context_col:\n",
        "            print(f\"(Based on {context_col})\")\n",
        "        for _, row in df.iterrows():\n",
        "            reason = []\n",
        "            if 'Similarity Score' in row and row['Similarity Score'] == 0:\n",
        "                reason.append(\"fallback (popular item)\")\n",
        "            elif 'Similarity Score' in row:\n",
        "                reason.append(f\"similarity score: {row['Similarity Score']:.4f}\")\n",
        "            if row['Category'] in top_cats:\n",
        "                reason.append(f\"matches favorite category: {row['Category']}\")\n",
        "            if row['Sub-Category'] in top_subcats:\n",
        "                reason.append(f\"matches frequent sub-category: {row['Sub-Category']}\")\n",
        "            explanation = \"; \".join(reason)\n",
        "            print(f\"→ {row['Product Name']} (ID: {row['Product ID']}) — {row['Category']} / {row['Sub-Category']}\")\n",
        "            if explanation:\n",
        "                print(f\"   Explanation: {explanation}\\n\")\n",
        "\n",
        "    # Generate all recommendations\n",
        "    popular_df = recommend_popular(customer_id, top_n=num_recommendations)\n",
        "    content_df = recommend_content_based(customer_id, top_n=num_recommendations)\n",
        "    collab_df = recommend_collaborative(customer_id, top_n=num_recommendations)\n",
        "    hybrid_df = recommend_hybrid(customer_id, top_n=num_recommendations, show_debug=True)\n",
        "\n",
        "    # Print all with explanations\n",
        "    explain_recommendations(\"Popular\", popular_df, context_col=\"overall purchase frequency across all users\")\n",
        "    explain_recommendations(\"Content-Based\", content_df, context_col=\"last product purchased\")\n",
        "    explain_recommendations(\"Collaborative\", collab_df, context_col=\"co-purchase patterns of similar users\")\n",
        "    explain_recommendations(\"Hybrid\", hybrid_df, context_col=\"content + collaborative + popularity\")\n",
        "\n",
        "# Example usage:\n",
        "print_recommendation_output(\"WB-21850\", num_recommendations=5)\n"
      ],
      "metadata": {
        "id": "IWmSoeATiZYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2e64d3-9d67-490e-8e17-3191d38399c1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Example: Personalized Recommendations for One Customer\n",
            "============================================================\n",
            "\n",
            " Purchase History Summary for Customer: WB-21850\n",
            "  - Total Unique Products Purchased: 36\n",
            "  - Most Recent Purchase: 'Contract Clock, 14\", Brown' on 2017-12-10 — Furniture / Furnishings\n",
            "  - Most Frequently Purchased Items:\n",
            "    → 'Fellowes 8 Outlet Superior Workstation Surge Protector' (2 times) — Office Supplies / Appliances\n",
            "    → 'Fellowes PB200 Plastic Comb Binding Machine' (1 times) — Office Supplies / Binders\n",
            "    → 'Motorla HX550 Universal Bluetooth Headset' (1 times) — Technology / Phones\n",
            "  - Top Categories: Office Supplies, Technology, Furniture\n",
            "  - Top Sub-Categories: Binders, Phones, Furnishings\n",
            "\n",
            " Customer Purchase History\n",
            "  [2017-12-10] Contract Clock, 14\", Brown (ID: FUR-FU-10001475) — Furniture / Furnishings\n",
            "  [2017-12-10] Heavy-Duty E-Z-D Binders (ID: OFF-BI-10000014) — Office Supplies / Binders\n",
            "  [2017-11-11] Vinyl Coated Wire Paper Clips in Organizer Box, 800/Box (ID: OFF-FA-10004854) — Office Supplies / Fasteners\n",
            "  [2017-06-29] GBC DocuBind TL200 Manual Binding Machine (ID: OFF-BI-10003091) — Office Supplies / Binders\n",
            "  [2017-06-29] Enermax Briskie RF Wireless Keyboard and Mouse Combo (ID: TEC-AC-10001284) — Technology / Accessories\n",
            "  [2017-06-29] Newell 328 (ID: OFF-AR-10000255) — Office Supplies / Art\n",
            "  [2017-06-29] Trav-L-File Heavy-Duty Shuttle II, Black (ID: OFF-ST-10002974) — Office Supplies / Storage\n",
            "  [2016-12-11] Rogers Profile Extra Capacity Storage Tub (ID: OFF-ST-10000636) — Office Supplies / Storage\n",
            "  [2016-12-11] IBM Multi-Purpose Copy Paper, 8 1/2 x 11\", Case (ID: OFF-PA-10000241) — Office Supplies / Paper\n",
            "  [2016-12-11] Microsoft Natural Ergonomic Keyboard 4000 (ID: TEC-AC-10000057) — Technology / Accessories\n",
            "  [2016-12-11] Global Wood Trimmed Manager's Task Chair, Khaki (ID: FUR-CH-10003774) — Furniture / Chairs\n",
            "  [2016-12-11] Recycled Easel Ring Binders (ID: OFF-BI-10002824) — Office Supplies / Binders\n",
            "  [2016-12-11] GBC Recycled VeloBinder Covers (ID: OFF-BI-10004001) — Office Supplies / Binders\n",
            "  [2016-12-11] Ibico Laser Imprintable Binding System Covers (ID: OFF-BI-10004593) — Office Supplies / Binders\n",
            "  [2016-12-11] Hon Non-Folding Utility Tables (ID: FUR-TA-10004619) — Furniture / Tables\n",
            "  [2016-12-11] Boston 16765 Mini Stand Up Battery Pencil Sharpener (ID: OFF-AR-10000914) — Office Supplies / Art\n",
            "  [2016-12-11] Fellowes 8 Outlet Superior Workstation Surge Protector (ID: OFF-AP-10001469) — Office Supplies / Appliances\n",
            "  [2016-12-11] Black Avery Memo-Size 3-Ring Binder, 5 1/2\" x 8 1/2\" (ID: OFF-BI-10002897) — Office Supplies / Binders\n",
            "  [2016-10-10] Eldon 400 Class Desk Accessories, Black Carbon (ID: FUR-FU-10004963) — Furniture / Furnishings\n",
            "  [2016-10-10] Wilson Jones Ledger-Size, Piano-Hinge Binder, 2\", Blue (ID: OFF-BI-10001597) — Office Supplies / Binders\n",
            "  [2016-01-15] Square Ring Data Binders, Rigid 75 Pt. Covers, 11\" x 14-7/8\" (ID: OFF-BI-10002225) — Office Supplies / Binders\n",
            "  [2016-01-15] Xerox 1959 (ID: OFF-PA-10004285) — Office Supplies / Paper\n",
            "  [2016-01-15] #10 Gummed Flap White Envelopes, 100/Box (ID: OFF-EN-10001137) — Office Supplies / Envelopes\n",
            "  [2015-11-30] Fellowes PB200 Plastic Comb Binding Machine (ID: OFF-BI-10003656) — Office Supplies / Binders\n",
            "  [2015-11-30] Revere Boxed Rubber Bands by Revere (ID: OFF-FA-10000053) — Office Supplies / Fasteners\n",
            "  [2015-11-30] Motorla HX550 Universal Bluetooth Headset (ID: TEC-PH-10002807) — Technology / Phones\n",
            "  [2015-08-10] Fellowes 8 Outlet Superior Workstation Surge Protector (ID: OFF-AP-10001469) — Office Supplies / Appliances\n",
            "  [2015-08-10] OtterBox Commuter Series Case - Samsung Galaxy S4 (ID: TEC-PH-10004188) — Technology / Phones\n",
            "  [2015-08-10] AT&T 1080 Corded phone (ID: TEC-PH-10000576) — Technology / Phones\n",
            "  [2014-12-20] Belkin Premiere Surge Master II 8-outlet surge protector (ID: OFF-AP-10001563) — Office Supplies / Appliances\n",
            "  [2014-12-20] Logitech Desktop MK120 Mouse and keyboard Combo (ID: TEC-AC-10004510) — Technology / Accessories\n",
            "  [2014-12-12] Eldon Advantage Chair Mats for Low to Medium Pile Carpets (ID: FUR-FU-10003975) — Furniture / Furnishings\n",
            "  [2014-11-04] Hewlett-Packard Deskjet D4360 Printer (ID: TEC-MA-10003246) — Technology / Machines\n",
            "  [2014-11-04] Xerox 2000 (ID: OFF-PA-10000223) — Office Supplies / Paper\n",
            "  [2014-11-04] Cardinal EasyOpen D-Ring Binders (ID: OFF-BI-10001036) — Office Supplies / Binders\n",
            "  [2014-11-04] Bevis Round Conference Table Top, X-Base (ID: FUR-TA-10002041) — Furniture / Tables\n",
            "  [2014-11-04] Polycom SoundPoint Pro SE-225 Corded phone (ID: TEC-PH-10001079) — Technology / Phones\n",
            "\n",
            "============================================================\n",
            " Recommendation Outputs\n",
            "============================================================\n",
            "Based on last product purchased (ID: FUR-FU-10001475): Contract Clock, 14\", Brown\n",
            "\n",
            "[DEBUG] Top products by each score (before final sort):\n",
            "                                           Product Name  content_score  collab_score  popularity_score  final_score\n",
            "215                        G.E. Halogen Desk Lamp Bulbs       0.573832      1.000000          0.135135     0.656560\n",
            "925                                             Staples       0.641505      0.513382          0.486486     0.559252\n",
            "966                            Avery File Folder Labels       0.422195      0.683422          0.581081     0.558463\n",
            "707           GBC DocuBind P50 Personal Binding Machine       0.637192      0.415808          0.662162     0.553632\n",
            "936                                             Staples       0.641505      0.485821          0.459459     0.542822\n",
            "702                     Wilson Jones Active Use Binders       0.281646      0.939828          0.270270     0.542644\n",
            "197   Floodlight Indoor Halogen Bulbs, 1 Bulb per Pa...       0.230887      0.960368          0.310811     0.538664\n",
            "795         Fellowes PB300 Plastic Comb Binding Machine       0.661699      0.440657          0.351351     0.511213\n",
            "658                               Avery Durable Binders       0.464438      0.449049          0.662162     0.497827\n",
            "1274                                          Xerox 212       0.354840      0.715952          0.324324     0.493182\n",
            "\n",
            "Top 5 Popular Recommendations:\n",
            "(Based on overall purchase frequency across all users)\n",
            "→ Logitech P710e Mobile Speakerphone (ID: TEC-AC-10003832) — Technology / Accessories\n",
            "   Explanation: matches favorite category: Technology; matches frequent sub-category: Accessories\n",
            "\n",
            "→ Xerox 1881 (ID: OFF-PA-10001970) — Office Supplies / Paper\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Paper\n",
            "\n",
            "→ GBC Premium Transparent Covers with Diagonal Lined Pattern (ID: OFF-BI-10001524) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Avery Arch Ring Binders (ID: OFF-BI-10002026) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Situations Contoured Folding Chairs, 4/Set (ID: FUR-CH-10002647) — Furniture / Chairs\n",
            "   Explanation: matches favorite category: Furniture; matches frequent sub-category: Chairs\n",
            "\n",
            "\n",
            "Top 5 Content-Based Recommendations:\n",
            "(Based on last product purchased)\n",
            "→ Avery 5 (ID: OFF-LA-10003388) — Office Supplies / Labels\n",
            "   Explanation: matches favorite category: Office Supplies\n",
            "\n",
            "→ Avery File Folder Labels (ID: OFF-LA-10001613) — Office Supplies / Labels\n",
            "   Explanation: matches favorite category: Office Supplies\n",
            "\n",
            "→ Avery Binder Labels (ID: OFF-BI-10000591) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Avery 50 (ID: OFF-LA-10004545) — Office Supplies / Labels\n",
            "   Explanation: matches favorite category: Office Supplies\n",
            "\n",
            "→ Avery 48 (ID: OFF-LA-10000121) — Office Supplies / Labels\n",
            "   Explanation: matches favorite category: Office Supplies\n",
            "\n",
            "\n",
            "Top 5 Collaborative Recommendations:\n",
            "(Based on co-purchase patterns of similar users)\n",
            "→ Floodlight Indoor Halogen Bulbs, 1 Bulb per Pack, 60 Watts (ID: FUR-FU-10001861) — Furniture / Furnishings\n",
            "   Explanation: similarity score: 0.0378; matches favorite category: Furniture; matches frequent sub-category: Furnishings\n",
            "\n",
            "→ G.E. Halogen Desk Lamp Bulbs (ID: FUR-FU-10002191) — Furniture / Furnishings\n",
            "   Explanation: similarity score: 0.0363; matches favorite category: Furniture; matches frequent sub-category: Furnishings\n",
            "\n",
            "→ Manco Dry-Lighter Erasable Highlighter (ID: OFF-AR-10000817) — Office Supplies / Art\n",
            "   Explanation: similarity score: 0.0355; matches favorite category: Office Supplies; matches frequent sub-category: Art\n",
            "\n",
            "→ Wilson Jones Active Use Binders (ID: OFF-BI-10001634) — Office Supplies / Binders\n",
            "   Explanation: similarity score: 0.0341; matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Zebra GK420t Direct Thermal/Thermal Transfer Printer (ID: TEC-MA-10001695) — Technology / Machines\n",
            "   Explanation: similarity score: 0.0313; matches favorite category: Technology; matches frequent sub-category: Machines\n",
            "\n",
            "\n",
            "Top 5 Hybrid Recommendations:\n",
            "(Based on content + collaborative + popularity)\n",
            "→ G.E. Halogen Desk Lamp Bulbs (ID: FUR-FU-10002191) — Furniture / Furnishings\n",
            "   Explanation: matches favorite category: Furniture; matches frequent sub-category: Furnishings\n",
            "\n",
            "→ Staples (ID: OFF-FA-10002780) — Office Supplies / Fasteners\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Fasteners\n",
            "\n",
            "→ Avery File Folder Labels (ID: OFF-LA-10001613) — Office Supplies / Labels\n",
            "   Explanation: matches favorite category: Office Supplies\n",
            "\n",
            "→ GBC DocuBind P50 Personal Binding Machine (ID: OFF-BI-10001718) — Office Supplies / Binders\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Binders\n",
            "\n",
            "→ Staples (ID: OFF-FA-10003495) — Office Supplies / Fasteners\n",
            "   Explanation: matches favorite category: Office Supplies; matches frequent sub-category: Fasteners\n",
            "\n"
          ]
        }
      ]
    }
  ]
}