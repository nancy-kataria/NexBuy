{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nancy-kataria/NexTrade/blob/main/product_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== Imports ==="
      ],
      "metadata": {
        "id": "TxLsn_3YgSds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FQjFG7BkiGKB"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "metadata": {
        "id": "cBKpCzmXbrpJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 1. Dataset Download ==="
      ],
      "metadata": {
        "id": "BitMW-zx-j2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "print(\"Dowlaod Dataset...\")\n",
        "path = kagglehub.dataset_download(\"vivek468/superstore-dataset-final\")\n",
        "print(f\"Dataset downloaded to: {path}\")\n",
        "csv_file_path = os.path.join(path, \"Sample - Superstore.csv\")\n",
        "print(f\"Reading data from: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "xj6z5B1j-nv7",
        "outputId": "5cbd5554-b5c0-46fe-eeb6-2155b2cb67c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dowlaod Dataset...\n",
            "Dataset downloaded to: /kaggle/input/superstore-dataset-final\n",
            "Reading data from: /kaggle/input/superstore-dataset-final/Sample - Superstore.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 2. Load & Clean Data ==="
      ],
      "metadata": {
        "id": "0fos8cod7pJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    superstore_data = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found at {csv_file_path}.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "Mh4kbf0HjNH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93132977-cdcd-45c0-d261-058851004ab7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep necessary columns\n",
        "columns_to_keep = ['Order ID', 'Order Date', 'Ship Date', 'Customer ID', 'Product ID', 'Product Name', 'Sales', 'Quantity', 'Category', 'Sub-Category']\n",
        "superstore_data = superstore_data[columns_to_keep]"
      ],
      "metadata": {
        "id": "_fTuhoxWlcUH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows to check the data\n",
        "print(\"First 5 rows of data:\")\n",
        "print(superstore_data.head())"
      ],
      "metadata": {
        "id": "4bSD5nfglcFi",
        "outputId": "9e12cd82-9cfb-4abe-eee2-58a9ef6e5891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of data:\n",
            "         Order ID  Order Date   Ship Date Customer ID       Product ID                                       Product Name     Sales  Quantity         Category Sub-Category\n",
            "0  CA-2016-152156   11/8/2016  11/11/2016    CG-12520  FUR-BO-10001798                  Bush Somerset Collection Bookcase  261.9600         2        Furniture    Bookcases\n",
            "1  CA-2016-152156   11/8/2016  11/11/2016    CG-12520  FUR-CH-10000454  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3        Furniture       Chairs\n",
            "2  CA-2016-138688   6/12/2016   6/16/2016    DV-13045  OFF-LA-10000240  Self-Adhesive Address Labels for Typewriters b...   14.6200         2  Office Supplies       Labels\n",
            "3  US-2015-108966  10/11/2015  10/18/2015    SO-20335  FUR-TA-10000577      Bretford CR4500 Series Slim Rectangular Table  957.5775         5        Furniture       Tables\n",
            "4  US-2015-108966  10/11/2015  10/18/2015    SO-20335  OFF-ST-10000760                     Eldon Fold 'N Roll Cart System   22.3680         2  Office Supplies      Storage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dates\n",
        "superstore_data['Order Date'] = pd.to_datetime(superstore_data['Order Date'])\n",
        "superstore_data['Ship Date'] = pd.to_datetime(superstore_data['Ship Date'])"
      ],
      "metadata": {
        "id": "v8JDsd7ZkKAk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if dropna() is overkill\n",
        "print(superstore_data[columns_to_keep].isnull().sum())"
      ],
      "metadata": {
        "id": "C96ihRBJcYV_",
        "outputId": "5f69db43-d5e1-4416-c434-536f00bc409b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Order ID        0\n",
            "Order Date      0\n",
            "Ship Date       0\n",
            "Customer ID     0\n",
            "Product ID      0\n",
            "Product Name    0\n",
            "Sales           0\n",
            "Quantity        0\n",
            "Category        0\n",
            "Sub-Category    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop rows with missing any necessary columns\n",
        "superstore_data.dropna(subset=columns_to_keep, inplace=True)"
      ],
      "metadata": {
        "id": "omwT_AcdkKXc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Finding Customers with Most Transactions ---\")\n",
        "\n",
        "# Count the number of rows (transaction line items) for each Customer ID\n",
        "customer_transaction_counts = superstore_data.groupby('Customer ID').size()\n",
        "\n",
        "# Sort the counts in descending order\n",
        "customer_transaction_counts_sorted = customer_transaction_counts.sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 5 Customers by Number of Transaction Entries:\")\n",
        "print(customer_transaction_counts_sorted.head(5))\n",
        "\n",
        "# Get the Customer ID with the absolute highest count\n",
        "if not customer_transaction_counts_sorted.empty:\n",
        "    top_customer_id = customer_transaction_counts_sorted.index[0]\n",
        "    top_customer_count = customer_transaction_counts_sorted.iloc[0]\n",
        "    print(f\"\\nCustomer with the most transaction entries: '{top_customer_id}' ({top_customer_count} entries)\")\n",
        "else:\n",
        "    top_customer_id = None # Handle case where data might be empty\n",
        "    print(\"\\nCould not determine top customer.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCw9orMdu8YU",
        "outputId": "4cb2cfe2-486d-4839-a490-2f453eb297b0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Finding Customers with Most Transactions ---\n",
            "Top 5 Customers by Number of Transaction Entries:\n",
            "Customer ID\n",
            "WB-21850    37\n",
            "MA-17560    34\n",
            "JL-15835    34\n",
            "PP-18955    34\n",
            "EH-13765    32\n",
            "dtype: int64\n",
            "\n",
            "Customer with the most transaction entries: 'WB-21850' (37 entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== (TEST STAGE) 2b. Evaluation Split (Time-Based) ==="
      ],
      "metadata": {
        "id": "n-pBRT2gpfWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Splitting Data for Evaluation ---\")\n",
        "# Sort data by order date\n",
        "superstore_data_sorted = superstore_data.sort_values('Order Date').copy()\n",
        "superstore_data_sorted.reset_index(drop=True, inplace=True) # Optional: Reset index\n",
        "\n",
        "# Define split point (e.g., 80% train, 20% test based on row count after sorting)\n",
        "# Alternatively, pick a specific date for splitting\n",
        "split_index = int(len(superstore_data_sorted) * 0.8)\n",
        "train_df = superstore_data_sorted.iloc[:split_index].copy()\n",
        "test_df = superstore_data_sorted.iloc[split_index:].copy()\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Testing data shape: {test_df.shape}\")\n",
        "if not train_df.empty:\n",
        "    print(f\"Training data period: {train_df['Order Date'].min()} to {train_df['Order Date'].max()}\")\n",
        "if not test_df.empty:\n",
        "    print(f\"Testing data period: {test_df['Order Date'].min()} to {test_df['Order Date'].max()}\")\n",
        "\n",
        "# Identify users present in the test set for evaluation\n",
        "test_users = test_df['Customer ID'].unique()\n",
        "print(f\"Number of unique users in test set: {len(test_users)}\")"
      ],
      "metadata": {
        "id": "0wNF5fG4pj3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 3. Precomputation  ==="
      ],
      "metadata": {
        "id": "go59KyXFg9VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Product Popularity\n",
        "product_popularity = superstore_data.groupby('Product ID').agg({\n",
        "    'Product Name': 'first',\n",
        "    'Category': 'first',\n",
        "    'Sub-Category': 'first',\n",
        "    'Quantity': 'sum',\n",
        "    'Sales': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Normalize popularity score\n",
        "product_popularity['popularity_score'] = product_popularity['Quantity'] / product_popularity['Quantity'].max()\n",
        "\n",
        "# 2. Content-Based Info Preparation\n",
        "superstore_data['product_info'] = (\n",
        "    superstore_data['Product Name'].astype(str) + ' ' +\n",
        "    superstore_data['Category'].astype(str) + ' ' +\n",
        "    superstore_data['Sub-Category'].astype(str)\n",
        ")\n",
        "\n",
        "# One row per product\n",
        "products = superstore_data.drop_duplicates(subset='Product ID')[\n",
        "    ['Product ID', 'Product Name', 'Category', 'Sub-Category', 'product_info']\n",
        "]\n",
        "\n",
        "# 3. TF-IDF Matrix and Cosine Similarity\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(products['product_info'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 4. Product Index Mapping\n",
        "product_indices = pd.Series(products.index, index=products['Product ID']).drop_duplicates()\n",
        "\n",
        "# 5. User-Product Matrix and Product Similarity for Collaborative Filtering\n",
        "# Create user-product interaction matrix\n",
        "user_product_matrix = superstore_data.pivot_table(\n",
        "    index='Customer ID',\n",
        "    columns='Product ID',\n",
        "    values='Quantity',\n",
        "    aggfunc='sum'\n",
        ").fillna(0)\n",
        "\n",
        "\n",
        "# Compute item-item similarity - similar to item you liked\n",
        "product_similarity = cosine_similarity(user_product_matrix.T)\n",
        "\n",
        "# Store as DataFrame\n",
        "product_similarity_df = pd.DataFrame(\n",
        "    product_similarity,\n",
        "    index=user_product_matrix.columns,\n",
        "    columns=user_product_matrix.columns\n",
        ")"
      ],
      "metadata": {
        "id": "c9fGWIFgg_Mp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 4. Recommendation Functions ==="
      ],
      "metadata": {
        "id": "M0vdvNDY7zWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Helper Functions ===\n",
        "def get_customer_orders_and_products(customer_id, df):\n",
        "    \"\"\"Fetches purchase data and unique purchased product IDs for a customer.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the target customer.\n",
        "        df (pd.DataFrame): The main DataFrame containing all transaction data.\n",
        "                           Must include 'Customer ID' and 'Product ID'.\n",
        "\n",
        "    Returns:\n",
        "        tuple[pd.DataFrame, np.ndarray]: A tuple containing:\n",
        "            - order_history (pd.DataFrame): A DataFrame filtered to only include\n",
        "                                            rows for the given customer_id. Returns\n",
        "                                            an empty DataFrame if customer not found.\n",
        "            - product_ids (np.ndarray): A NumPy array of unique Product IDs\n",
        "                                          purchased by the customer. Returns an\n",
        "                                          empty array if customer not found.\n",
        "    \"\"\"\n",
        "    order_history = df[df['Customer ID'] == customer_id].copy()\n",
        "    # Using .copy() is good practice here to prevent potential SettingWithCopyWarning\n",
        "    # if the returned DataFrame is modified later in another function.\n",
        "    product_ids = order_history['Product ID'].unique()\n",
        "    return order_history, product_ids\n",
        "\n",
        "def get_unseen_products(customer_id, df, product_df):\n",
        "    \"\"\"\n",
        "    Get a list of products the customer hasn't purchased yet\n",
        "\n",
        "    Args:\n",
        "      customer_id (str): ID of the target customer.\n",
        "      df (pd.DataFrame): Full transaction data (e.g., superstore_data)\n",
        "                           used to find customer history.\n",
        "      product_df (pd.DataFrame): DataFrame of all products to recommend\n",
        "                                   from (e.g., product_popularity).\n",
        "\n",
        "    Returns:\n",
        "      pd.DataFrame: filtered product_df with only unseen products\n",
        "      pd.DataFrame: list of purchased Product IDs for fallback logic\n",
        "    \"\"\"\n",
        "\n",
        "    _, product_ids = get_customer_orders_and_products(customer_id, df)\n",
        "    return product_df[~product_df['Product ID'].isin(product_ids)], product_ids\n",
        "\n",
        "def add_fallback_if_needed(recommendations, product_ids, product_df, n, by):\n",
        "    \"\"\"\n",
        "    Add fallback recommendations if there aren't enough unseen products to recommend\n",
        "    This uses globally popular products (based on 'Quantity' or 'Sales') to fill the gap\n",
        "\n",
        "    Args:\n",
        "      recommendations: filtered list of unseen, ranked products\n",
        "      purchased_ids: list of already purchased product IDs\n",
        "      product_df: global product list (e.g., product_popularity)\n",
        "      n: number of products we want to recommend\n",
        "      by: popularity metric ('Quantity' or 'Sales')\n",
        "\n",
        "    Returns:\n",
        "     pd.DataFrame: final DataFrame of n recommendations\n",
        "    \"\"\"\n",
        "\n",
        "    if len(recommendations) < n:\n",
        "        print(f\"Customer has only {len(recommendations)} new products available. Showing global popular items instead.\")\n",
        "        fallback = get_global_popular_products(n=n, by=by)\n",
        "        fallback = fallback[~fallback['Product ID'].isin(product_ids)]\n",
        "        recommendations = pd.concat([recommendations, fallback]).drop_duplicates('Product ID')\n",
        "    return recommendations\n",
        "\n",
        "def get_customer_preferences(customer_id, df):\n",
        "    \"\"\"\n",
        "    Gets the customer's most frequent categories and sub-categories.\n",
        "\n",
        "    Analyzes a customer's purchase history to find the categories and\n",
        "    sub-categories they interact with most often, based on the count\n",
        "    of purchases in each. Used for personalized popularity recommendations.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the target customer.\n",
        "        df (pd.DataFrame): The DataFrame containing transaction data, including\n",
        "                           'Customer ID', 'Category', and 'Sub-Category' columns.\n",
        "\n",
        "    Returns:\n",
        "        tuple[list[str], list[str]]: A tuple containing two lists:\n",
        "            - The first list contains category names, sorted by frequency (most frequent first).\n",
        "            - The second list contains sub-category names, sorted by frequency.\n",
        "            Returns two empty lists ([], []) if the customer has no purchase history in df.\n",
        "    \"\"\"\n",
        "    order_history, _ = get_customer_orders_and_products(customer_id, df)\n",
        "    if order_history.empty:\n",
        "        return [], []\n",
        "    top_categories = order_history['Category'].value_counts().index.tolist()\n",
        "    top_subcategories = order_history['Sub-Category'].value_counts().index.tolist()\n",
        "    return top_categories, top_subcategories"
      ],
      "metadata": {
        "id": "SsHMrd2VkK9y"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Calculation  Functions ===\n",
        "def get_global_popular_products(n=10, by='Quantity'):\n",
        "    \"\"\"\n",
        "    Recommends top-N globally popular products. Sorts all products based on a specified metric ('Quantity' or 'Sales') and returns the top N. Does not consider customer history.\n",
        "\n",
        "    Args:\n",
        "        n (int, optional): The number of products to recommend. Defaults to 10.\n",
        "        by (str, optional): The metric to sort popularity by ('Quantity' or 'Sales'). Defaults to 'Quantity'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the top N popular products with columns ['Product ID', 'Product Name', 'Category', 'Sub-Category', <by>]. Returns an empty DataFrame if an invalid 'by' parameter is provided (though it currently raises ValueError).\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If 'by' is not 'Quantity' or 'Sales'.\n",
        "    \"\"\"\n",
        "    if by not in ['Quantity', 'Sales']:\n",
        "        raise ValueError(\"Parameter 'by' must be either 'Quantity' or 'Sales'\")\n",
        "\n",
        "    return product_popularity.sort_values(by=by, ascending=False).head(n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', by]]\n",
        "\n",
        "def get_content_similar_items(product_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends products similar to a given product based on content.\n",
        "\n",
        "      Uses precomputed TF-IDF vectors and cosine similarity based on product\n",
        "      name, category, and sub-category.\n",
        "\n",
        "      Args:\n",
        "          product_id (str): The ID of the product to find similar items for.\n",
        "          top_n (int, optional): The number of similar products to return.\n",
        "                                Defaults to 5.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A DataFrame containing the top_n similar products with\n",
        "                        columns ['Product Name', 'Category', 'Sub-Category'].\n",
        "                        Returns an empty DataFrame if the product_id is not found.\n",
        "      \"\"\"\n",
        "    if product_id not in product_indices.index:\n",
        "      print(f\"Product ID '{product_id}' not found in product indices.\")\n",
        "      return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    idx = product_indices[product_id]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "    product_idxs = [i[0] for i in sim_scores]\n",
        "\n",
        "    return products.iloc[product_idxs][['Product ID', 'Product Name', 'Category', 'Sub-Category']]\n",
        "\n",
        "def get_collaborative_similar_items(product_id, top_n=5):\n",
        "    \"\"\"Recommends products similar to a given product using item-item collaborative filtering.\n",
        "\n",
        "    Uses a precomputed product similarity matrix based on user co-purchase patterns.\n",
        "\n",
        "    Args:\n",
        "        product_id (str): The ID of the product to find collaboratively similar items for.\n",
        "        top_n (int, optional): The number of similar products to return. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the top_n similar products\n",
        "                             with columns ['Product ID', 'Similarity Score', 'Product Name',\n",
        "                             'Category', 'Sub-Category']. Returns a string message if the\n",
        "                             product_id is not found in the similarity matrix. (Consider\n",
        "                             changing string returns to an empty DataFrame).\n",
        "    \"\"\"\n",
        "\n",
        "    if product_id not in product_similarity_df.columns:\n",
        "        print(f\"Product {product_id} not found in dataset.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "    similar_scores = product_similarity_df[product_id].sort_values(ascending=False)\n",
        "    # return similar_scores[1:top_n+1]\n",
        "\n",
        "    recommended = similar_scores[1:top_n+1].reset_index()\n",
        "    recommended.columns = ['Product ID', 'Similarity Score']\n",
        "    return recommended.merge(\n",
        "        product_popularity[['Product ID', 'Product Name', 'Category', 'Sub-Category']],\n",
        "        on='Product ID', how='left'\n",
        "    )"
      ],
      "metadata": {
        "id": "upq_-CyItnj0"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Main Recommendation Functions ===\n",
        "def recommend_popular(customer_id=None, top_n=10, by='Quantity'):\n",
        "    \"\"\"\n",
        "    Recommends popular products, optionally personalized for a customer.\n",
        "\n",
        "    Modes:\n",
        "    1. Global: If customer_id is None, returns globally popular products.\n",
        "    2. Unseen for Customer: Returns globally popular products not yet purchased by the customer,\n",
        "       with fallback if fewer than n are found.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str, optional): The ID of the customer. Defaults to None.\n",
        "        n (int, optional): The number of products to recommend. Defaults to 10.\n",
        "        by (str, optional): The metric for popularity ('Quantity' or 'Sales').\n",
        "                            Defaults to 'Quantity'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Top-N recommended products.\n",
        "\n",
        "    \"\"\"\n",
        "    if by not in ['Quantity', 'Sales']:\n",
        "        raise ValueError(\"Parameter 'by' must be either 'Quantity' or 'Sales'\")\n",
        "\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(n=top_n)\n",
        "\n",
        "    # Case 2: Exclude products already purchased\n",
        "    unseen_products, product_ids = get_unseen_products(customer_id, superstore_data, product_popularity)\n",
        "    unseen_products = unseen_products.sort_values(by=by, ascending=False)\n",
        "\n",
        "    # Apply fallback if needed\n",
        "    final = add_fallback_if_needed(unseen_products, product_ids, product_popularity, top_n, by)\n",
        "\n",
        "    return final.head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category', by]]\n",
        "\n",
        "def recommend_content_based(customer_id, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends products similar to the last item purchased by a customer.\n",
        "\n",
        "    Finds the customer's most recent purchase and then uses content-based\n",
        "    similarity (get_content_similar_items) to find similar items.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the customer.\n",
        "        top_n (int, optional): The number of similar products to recommend.\n",
        "                               Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the recommended products\n",
        "                             (from get_content_similar_items) or a string message\n",
        "                             if the customer has no purchase history.\n",
        "                             (Consider changing the string return to an empty DataFrame\n",
        "                             for consistency).\n",
        "    \"\"\"\n",
        "    # Case 1: No customer → return top global products\n",
        "    if customer_id is None:\n",
        "        print(\"No customer ID provided. Returning global popular products.\")\n",
        "        return get_global_popular_products(n=top_n)\n",
        "\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "          print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "          return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # Get last product bought\n",
        "    last_purchase = order_history.sort_values('Order Date', ascending=False).iloc[0]\n",
        "    last_product_id = last_purchase['Product ID']\n",
        "    last_product_name = last_purchase['Product Name']\n",
        "    print(f\"Based on last product purchased (ID: {last_product_id}): {last_product_name}\")\n",
        "\n",
        "    # Get content-based similar items\n",
        "    similar_items = get_content_similar_items(last_product_id, top_n * 2)  # get more to allow filtering\n",
        "\n",
        "    # Exclude already purchased\n",
        "    similar_items = similar_items[~similar_items['Product ID'].isin(product_ids)]\n",
        "\n",
        "    return similar_items.head(top_n)[['Product ID', 'Product Name', 'Category', 'Sub-Category']]\n",
        "\n",
        "def recommend_collaborative(customer_id, top_n=5):\n",
        "    \"\"\"Recommends products to a customer based on collaborative filtering.\n",
        "\n",
        "    Aggregates similarity scores from items the customer has purchased to find\n",
        "    new items that are similar based on co-purchase patterns across all users.\n",
        "    Excludes items already purchased by the customer.\n",
        "\n",
        "    Args:\n",
        "        customer_id (str): The ID of the customer.\n",
        "        top_n (int, optional): The number of products to recommend. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame or str: A DataFrame containing the top_n recommended products\n",
        "                             with columns ['Product ID', 'Product Name', 'Category',\n",
        "                             'Sub-Category']. Returns a string message if the customer\n",
        "                             has no history or suitable product data isn't found.\n",
        "                             (Consider changing string returns to an empty DataFrame).\n",
        "    \"\"\"\n",
        "\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "        print(f\"No purchase history for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # If user has multiple purchases, accumulate similarity\n",
        "    sim_scores = None\n",
        "    for pid in product_ids:\n",
        "        if pid not in product_similarity_df.columns:\n",
        "            continue\n",
        "        product_scores = product_similarity_df[pid]\n",
        "        sim_scores = product_scores if sim_scores is None else sim_scores + product_scores\n",
        "\n",
        "    if sim_scores is None:\n",
        "        print(f\"No valid products found for similarity for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame() # Or an empty list\n",
        "\n",
        "    # Normalize if multiple products\n",
        "    sim_scores = sim_scores / len(product_ids)\n",
        "\n",
        "    # Remove already purchased products\n",
        "    sim_scores = sim_scores.drop(labels=product_ids, errors='ignore')\n",
        "\n",
        "    # Top N similar products\n",
        "    top_ids = sim_scores.sort_values(ascending=False).head(top_n).index\n",
        "\n",
        "    return product_popularity[product_popularity['Product ID'].isin(top_ids)][[\n",
        "        'Product ID', 'Product Name', 'Category', 'Sub-Category'\n",
        "    ]]\n",
        "\n",
        "def recommend_hybrid(customer_id, top_n=5, w_content=0.4, w_collab=0.4, w_pop=0.2):\n",
        "    \"\"\"\n",
        "    Recommends products using a hybrid approach combining content similarity,\n",
        "    collaborative similarity, and global popularity.\n",
        "    \"\"\"\n",
        "    order_history, product_ids = get_customer_orders_and_products(customer_id, superstore_data)\n",
        "    if order_history.empty:\n",
        "        print(f\"No purchase history found for customer '{customer_id}'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # --- 1. Calculate Average Content Similarity Scores ---\n",
        "    purchased_idxs_content = [product_indices[pid] for pid in product_ids if pid in product_indices]\n",
        "    if not purchased_idxs_content:\n",
        "        print(f\"No purchased products for customer '{customer_id}' found in content product index.\")\n",
        "        # Could potentially proceed without content score or return empty\n",
        "        avg_content_sim_scores = np.zeros(len(products)) # Assign zero score if no history match\n",
        "    else:\n",
        "        # Average similarity to user's purchase history\n",
        "        valid_idxs = [idx for idx in purchased_idxs_content if idx < cosine_sim.shape[0]]\n",
        "        if not valid_idxs:\n",
        "            print(f\"No valid content-based product indices for customer '{customer_id}'.\")\n",
        "            avg_content_sim_scores = np.zeros(len(products))\n",
        "        else:\n",
        "            avg_content_sim_scores = sum(cosine_sim[idx] for idx in valid_idxs) / len(valid_idxs)\n",
        "\n",
        "    content_df = pd.DataFrame({\n",
        "        'Product ID': products['Product ID'], # Use Product ID from the 'products' DataFrame\n",
        "        'content_score': avg_content_sim_scores\n",
        "    })\n",
        "\n",
        "    # --- 2. Calculate Average Collaborative Similarity Scores ---\n",
        "    sim_scores_collab = None\n",
        "    valid_purchased_ids_count = 0\n",
        "    for pid in product_ids:\n",
        "        if pid not in product_similarity_df.columns:\n",
        "            continue\n",
        "        product_scores = product_similarity_df[pid]\n",
        "        sim_scores_collab = product_scores if sim_scores_collab is None else sim_scores_collab + product_scores\n",
        "        valid_purchased_ids_count += 1\n",
        "\n",
        "    if sim_scores_collab is None:\n",
        "        print(f\"No valid products found for collaborative similarity for customer '{customer_id}'.\")\n",
        "         # Assign zero score if no history match in collaborative matrix\n",
        "        collab_df = pd.DataFrame({'Product ID': product_similarity_df.columns, 'collab_score': 0.0})\n",
        "    else:\n",
        "        avg_collab_sim_scores = sim_scores_collab / valid_purchased_ids_count\n",
        "        collab_df = avg_collab_sim_scores.reset_index()\n",
        "        collab_df.columns = ['Product ID', 'collab_score']\n",
        "\n",
        "    # --- 3. Combine Scores ---\n",
        "    # Start with all products and their popularity\n",
        "    combined_df = product_popularity[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'popularity_score']].copy()\n",
        "\n",
        "    # Merge content scores\n",
        "    combined_df = pd.merge(combined_df, content_df, on='Product ID', how='left')\n",
        "    combined_df['content_score'] = combined_df['content_score'].fillna(0) # Handle products not in content matrix (if any)\n",
        "\n",
        "    # Merge collaborative scores\n",
        "    combined_df = pd.merge(combined_df, collab_df, on='Product ID', how='left')\n",
        "    combined_df['collab_score'] = combined_df['collab_score'].fillna(0) # Handle products not in collab matrix\n",
        "\n",
        "    # Filter out already purchased items\n",
        "    combined_df = combined_df[~combined_df['Product ID'].isin(product_ids)]\n",
        "\n",
        "    # Calculate final hybrid score\n",
        "    combined_df['final_score'] = (\n",
        "        w_content * combined_df['content_score'] +\n",
        "        w_collab * combined_df['collab_score'] +\n",
        "        w_pop * combined_df['popularity_score']\n",
        "    )\n",
        "\n",
        "    # Get top N recommendations\n",
        "    final_recommendations = combined_df.sort_values(by='final_score', ascending=False).head(top_n)\n",
        "\n",
        "    return final_recommendations[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'final_score']]"
      ],
      "metadata": {
        "id": "QNVYBKdItr0g"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 5. Example Usage ==="
      ],
      "metadata": {
        "id": "hTLkJLiOity3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if top_customer_id:\n",
        "     customer_example_id = top_customer_id\n",
        "else:\n",
        "     print(\"WARN: Using default customer ID as top customer wasn't found.\")\n",
        "     customer_example_id = 'CG-12520' # Fallback to original if needed\n",
        "\n",
        "num_recommendations = 5\n",
        "\n",
        "order_history, product_ids = get_customer_orders_and_products(customer_example_id, superstore_data)\n",
        "\n",
        "if order_history.empty:\n",
        "    print(f\"\\nWARN: No purchase history found for example customer '{customer_example_id}'. Cannot show context.\")\n",
        "    # Depending on your functions, recommendations might still work (e.g., global popular) or return empty.\n",
        "else:\n",
        "    print(f\"\\nCustomer Purchase Context (from full history):\")\n",
        "    print(f\"  Total Unique Products Purchased: {len(product_ids)}\")\n",
        "\n",
        "    # --- Last Purchase ---\n",
        "    # Sort by date to find the most recent purchase in the full history\n",
        "    customer_history_context_sorted = order_history.sort_values('Order Date', ascending=False)\n",
        "    last_purchase = customer_history_context_sorted.iloc[0]\n",
        "    print(f\"  Last Purchase (on {last_purchase['Order Date'].date()}):\")\n",
        "    print(f\"    - Product: '{last_purchase['Product Name']}' (ID: {last_purchase['Product ID']})\")\n",
        "    # Note: recommend_content_based uses this logic internally. Printing it here gives context.\n",
        "\n",
        "    # --- Most Frequent Purchases (e.g., Top 3) ---\n",
        "    print(f\"  Most Frequent Purchases:\")\n",
        "    # Count occurrences of each product ID in the history\n",
        "    freq_counts = order_history['Product ID'].value_counts()\n",
        "    # Get names for the top IDs\n",
        "    top_freq_ids = freq_counts.head(3).index.tolist()\n",
        "    # Look up names (using product_popularity which has unique IDs and names)\n",
        "    top_freq_products = product_popularity[product_popularity['Product ID'].isin(top_freq_ids)][['Product ID', 'Product Name']]\n",
        "    # Merge to show count (optional, simpler to just list names)\n",
        "    for pid in top_freq_ids:\n",
        "         name = top_freq_products[top_freq_products['Product ID'] == pid]['Product Name'].iloc[0]\n",
        "         count = freq_counts[pid]\n",
        "         print(f\"    - '{name}' ({count} times)\")\n",
        "\n",
        "\n",
        "    # --- Top Categories/Sub-Categories ---\n",
        "    # Use the helper function to get preferences from the full history\n",
        "    top_cats, top_subcats = get_customer_preferences(customer_example_id, superstore_data)\n",
        "    print(f\"  Top Categories (by purchase frequency): {top_cats[:3]}\") # Show top 3\n",
        "    print(f\"  Top Sub-Categories (by purchase frequency): {top_subcats[:3]}\") # Show top 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1hBdbzGuJRU",
        "outputId": "ee7eb22e-2848-4f41-9227-cbb596b5cf8e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Customer Purchase Context (from full history):\n",
            "  Total Unique Products Purchased: 36\n",
            "  Last Purchase (on 2017-12-10):\n",
            "    - Product: 'Contract Clock, 14\", Brown' (ID: FUR-FU-10001475)\n",
            "  Most Frequent Purchases:\n",
            "    - 'Fellowes 8 Outlet Superior Workstation Surge Protector' (2 times)\n",
            "    - 'Fellowes PB200 Plastic Comb Binding Machine' (1 times)\n",
            "    - 'Motorla HX550 Universal Bluetooth Headset' (1 times)\n",
            "  Top Categories (by purchase frequency): ['Office Supplies', 'Technology', 'Furniture']\n",
            "  Top Sub-Categories (by purchase frequency): ['Binders', 'Phones', 'Furnishings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Display Recommendations ---\n",
        "print(\"\\n--- Generating Recommendations ---\")\n",
        "\n",
        "print(f\"\\nTop {num_recommendations} Popular Products (Unseen by Customer):\")\n",
        "print(recommend_popular(customer_id=customer_example_id, top_n=num_recommendations))\n",
        "\n",
        "print(f\"\\nTop {num_recommendations} Content-Based Recommendations (Based on Last Purchase):\")\n",
        "print(recommend_content_based(customer_example_id, top_n=num_recommendations))\n",
        "\n",
        "print(f\"\\nTop {num_recommendations} Collaborative Recommendations (Based on Customer History):\")\n",
        "print(recommend_collaborative(customer_example_id, top_n=num_recommendations))\n",
        "\n",
        "print(f\"\\nTop {num_recommendations} Advanced Hybrid Recommendations (Content+Collab+Pop):\")\n",
        "print(recommend_hybrid(customer_example_id, top_n=num_recommendations))"
      ],
      "metadata": {
        "id": "45HD3ts26V_e",
        "outputId": "cc447360-8cb4-44ef-f7ea-d6a4ee307460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating Recommendations ---\n",
            "\n",
            "Top 5 Popular Products (Unseen by Customer):\n",
            "           Product ID                                       Product Name         Category Sub-Category  Quantity\n",
            "1569  TEC-AC-10003832                 Logitech P710e Mobile Speakerphone       Technology  Accessories        75\n",
            "1144  OFF-PA-10001970                                         Xerox 1881  Office Supplies        Paper        70\n",
            "694   OFF-BI-10001524  GBC Premium Transparent Covers with Diagonal L...  Office Supplies      Binders        67\n",
            "721   OFF-BI-10002026                            Avery Arch Ring Binders  Office Supplies      Binders        64\n",
            "93    FUR-CH-10002647         Situations Contoured Folding Chairs, 4/Set        Furniture       Chairs        64\n",
            "\n",
            "Top 5 Content-Based Recommendations (Based on Last Purchase):\n",
            "Based on last product purchased (ID: FUR-FU-10001475): Contract Clock, 14\", Brown\n",
            "                  Product Name         Category Sub-Category\n",
            "4550                   Avery 5  Office Supplies       Labels\n",
            "963   Avery File Folder Labels  Office Supplies       Labels\n",
            "1609       Avery Binder Labels  Office Supplies      Binders\n",
            "2475                  Avery 50  Office Supplies       Labels\n",
            "1281                  Avery 48  Office Supplies       Labels\n",
            "\n",
            "Top 5 Collaborative Recommendations (Based on Customer History):\n",
            "           Product ID                                       Product Name         Category Sub-Category\n",
            "197   FUR-FU-10001861  Floodlight Indoor Halogen Bulbs, 1 Bulb per Pa...        Furniture  Furnishings\n",
            "215   FUR-FU-10002191                       G.E. Halogen Desk Lamp Bulbs        Furniture  Furnishings\n",
            "495   OFF-AR-10000817             Manco Dry-Lighter Erasable Highlighter  Office Supplies          Art\n",
            "702   OFF-BI-10001634                    Wilson Jones Active Use Binders  Office Supplies      Binders\n",
            "1635  TEC-MA-10001695  Zebra GK420t Direct Thermal/Thermal Transfer P...       Technology     Machines\n",
            "\n",
            "Top 5 Advanced Hybrid Recommendations (Content+Collab+Pop):\n",
            "           Product ID                                       Product Name         Category Sub-Category  final_score\n",
            "1569  TEC-AC-10003832                 Logitech P710e Mobile Speakerphone       Technology  Accessories     0.205096\n",
            "1144  OFF-PA-10001970                                         Xerox 1881  Office Supplies        Paper     0.204604\n",
            "721   OFF-BI-10002026                            Avery Arch Ring Binders  Office Supplies      Binders     0.194175\n",
            "694   OFF-BI-10001524  GBC Premium Transparent Covers with Diagonal L...  Office Supplies      Binders     0.191955\n",
            "93    FUR-CH-10002647         Situations Contoured Folding Chairs, 4/Set        Furniture       Chairs     0.176610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=== 6. Evaluation ==="
      ],
      "metadata": {
        "id": "RxDkBumng3q2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWmSoeATiZYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}